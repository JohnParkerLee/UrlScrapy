2019-Jun-09 18:10:40 log.py[line:146]/INFO/  Scrapy 1.6.0 started (bot: urlScrapy)
2019-Jun-09 18:10:40 log.py[line:149]/INFO/  Versions: lxml 4.3.3.0, libxml2 2.9.8, cssselect 1.0.3, parsel 1.5.1, w3lib 1.20.0, Twisted 19.2.0, Python 3.7.3 | packaged by conda-forge | (default, Mar 27 2019, 23:18:50) [MSC v.1900 64 bit (AMD64)], pyOpenSSL 19.0.0 (OpenSSL 1.1.1c  28 May 2019), cryptography 2.6.1, Platform Windows-10-10.0.17134-SP0
2019-Jun-09 18:10:40 crawler.py[line:38]/INFO/  Overridden settings: {'BOT_NAME': 'urlScrapy', 'CONCURRENT_REQUESTS': 10, 'CONCURRENT_REQUESTS_PER_DOMAIN': 10, 'CONCURRENT_REQUESTS_PER_IP': 10, 'DOWNLOAD_DELAY': 5, 'NEWSPIDER_MODULE': 'urlScrapy.spiders', 'ROBOTSTXT_OBEY': True, 'SPIDER_MODULES': ['urlScrapy.spiders']}
2019-Jun-09 18:10:40 telnet.py[line:60]/INFO/  Telnet Password: f956a82a47b066a2
2019-Jun-09 18:10:40 middleware.py[line:48]/INFO/  Enabled extensions:
['scrapy.extensions.corestats.CoreStats',
 'scrapy.extensions.telnet.TelnetConsole',
 'scrapy.extensions.logstats.LogStats']
2019-Jun-09 18:10:41 middleware.py[line:48]/INFO/  Enabled downloader middlewares:
['proxyPool.scrapy.middlewares.RetryMiddleware',
 'scrapy.downloadermiddlewares.robotstxt.RobotsTxtMiddleware',
 'proxyPool.scrapy.middlewares.ProxyMiddleware',
 'proxyPool.scrapy.middlewares.CatchExceptionMiddleware',
 'scrapy.downloadermiddlewares.httpauth.HttpAuthMiddleware',
 'scrapy.downloadermiddlewares.downloadtimeout.DownloadTimeoutMiddleware',
 'scrapy.downloadermiddlewares.defaultheaders.DefaultHeadersMiddleware',
 'proxyPool.scrapy.RandomUserAgentMiddleware.RandomUserAgentMiddleware',
 'scrapy.downloadermiddlewares.useragent.UserAgentMiddleware',
 'scrapy.downloadermiddlewares.retry.RetryMiddleware',
 'scrapy.downloadermiddlewares.redirect.MetaRefreshMiddleware',
 'scrapy.downloadermiddlewares.httpcompression.HttpCompressionMiddleware',
 'scrapy.downloadermiddlewares.redirect.RedirectMiddleware',
 'scrapy.downloadermiddlewares.cookies.CookiesMiddleware',
 'scrapy.downloadermiddlewares.httpproxy.HttpProxyMiddleware',
 'scrapy.downloadermiddlewares.stats.DownloaderStats']
2019-Jun-09 18:10:41 middleware.py[line:48]/INFO/  Enabled spider middlewares:
['scrapy.spidermiddlewares.httperror.HttpErrorMiddleware',
 'scrapy.spidermiddlewares.offsite.OffsiteMiddleware',
 'scrapy.spidermiddlewares.referer.RefererMiddleware',
 'scrapy.spidermiddlewares.urllength.UrlLengthMiddleware',
 'scrapy.spidermiddlewares.depth.DepthMiddleware']
2019-Jun-09 18:10:41 middleware.py[line:48]/INFO/  Enabled item pipelines:
['urlScrapy.pipelines.UrlscrapyPipeline']
2019-Jun-09 18:10:41 engine.py[line:256]/INFO/  Spider opened
2019-Jun-09 18:10:41 logstats.py[line:48]/INFO/  Crawled 0 pages (at 0 pages/min), scraped 0 items (at 0 items/min)
2019-Jun-09 18:10:41 telnet.py[line:74]/INFO/  Telnet console listening on 127.0.0.1:6023
2019-Jun-09 18:10:41 proxyDBManager.py[line:144]/ERROR/  ===== select random_proxy exception =====
 'NoneType' object is not subscriptable
Traceback (most recent call last):
  File "E:\urlScrapy\proxyPool\dbManager\proxyDBManager.py", line 140, in select_random_proxy
    proxy = str(data[1], encoding="utf-8").lower() + "://" + str(data[0], encoding="utf-8") + ":" + str(data[2])
TypeError: 'NoneType' object is not subscriptable
2019-Jun-09 18:10:41 proxyDBManager.py[line:144]/ERROR/  ===== select random_proxy exception =====
 'NoneType' object is not subscriptable
Traceback (most recent call last):
  File "E:\urlScrapy\proxyPool\dbManager\proxyDBManager.py", line 140, in select_random_proxy
    proxy = str(data[1], encoding="utf-8").lower() + "://" + str(data[0], encoding="utf-8") + ":" + str(data[2])
TypeError: 'NoneType' object is not subscriptable
2019-Jun-09 18:10:41 middlewares.py[line:19]/DEBUG/  =====  ProxyMiddleware get a random_proxy:¡¾ None ¡¿ =====
