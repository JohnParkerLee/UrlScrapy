2019-Jun-09 18:22:12 log.py[line:146]/INFO/  Scrapy 1.6.0 started (bot: urlScrapy)
2019-Jun-09 18:22:12 log.py[line:149]/INFO/  Versions: lxml 4.3.3.0, libxml2 2.9.8, cssselect 1.0.3, parsel 1.5.1, w3lib 1.20.0, Twisted 19.2.0, Python 3.7.3 | packaged by conda-forge | (default, Mar 27 2019, 23:18:50) [MSC v.1900 64 bit (AMD64)], pyOpenSSL 19.0.0 (OpenSSL 1.1.1c  28 May 2019), cryptography 2.6.1, Platform Windows-10-10.0.17134-SP0
2019-Jun-09 18:22:12 crawler.py[line:38]/INFO/  Overridden settings: {'BOT_NAME': 'urlScrapy', 'CONCURRENT_REQUESTS': 10, 'CONCURRENT_REQUESTS_PER_DOMAIN': 10, 'CONCURRENT_REQUESTS_PER_IP': 10, 'DOWNLOAD_DELAY': 5, 'NEWSPIDER_MODULE': 'urlScrapy.spiders', 'ROBOTSTXT_OBEY': True, 'SPIDER_MODULES': ['urlScrapy.spiders']}
2019-Jun-09 18:22:12 telnet.py[line:60]/INFO/  Telnet Password: c4bc5d77f2c3850b
2019-Jun-09 18:22:12 middleware.py[line:48]/INFO/  Enabled extensions:
['scrapy.extensions.corestats.CoreStats',
 'scrapy.extensions.telnet.TelnetConsole',
 'scrapy.extensions.logstats.LogStats']
2019-Jun-09 18:22:12 middleware.py[line:48]/INFO/  Enabled downloader middlewares:
['proxyPool.scrapy.middlewares.RetryMiddleware',
 'scrapy.downloadermiddlewares.robotstxt.RobotsTxtMiddleware',
 'proxyPool.scrapy.middlewares.ProxyMiddleware',
 'proxyPool.scrapy.middlewares.CatchExceptionMiddleware',
 'scrapy.downloadermiddlewares.httpauth.HttpAuthMiddleware',
 'scrapy.downloadermiddlewares.downloadtimeout.DownloadTimeoutMiddleware',
 'scrapy.downloadermiddlewares.defaultheaders.DefaultHeadersMiddleware',
 'proxyPool.scrapy.RandomUserAgentMiddleware.RandomUserAgentMiddleware',
 'scrapy.downloadermiddlewares.useragent.UserAgentMiddleware',
 'scrapy.downloadermiddlewares.retry.RetryMiddleware',
 'scrapy.downloadermiddlewares.redirect.MetaRefreshMiddleware',
 'scrapy.downloadermiddlewares.httpcompression.HttpCompressionMiddleware',
 'scrapy.downloadermiddlewares.redirect.RedirectMiddleware',
 'scrapy.downloadermiddlewares.cookies.CookiesMiddleware',
 'scrapy.downloadermiddlewares.httpproxy.HttpProxyMiddleware',
 'scrapy.downloadermiddlewares.stats.DownloaderStats']
2019-Jun-09 18:22:12 middleware.py[line:48]/INFO/  Enabled spider middlewares:
['scrapy.spidermiddlewares.httperror.HttpErrorMiddleware',
 'scrapy.spidermiddlewares.offsite.OffsiteMiddleware',
 'scrapy.spidermiddlewares.referer.RefererMiddleware',
 'scrapy.spidermiddlewares.urllength.UrlLengthMiddleware',
 'scrapy.spidermiddlewares.depth.DepthMiddleware']
2019-Jun-09 18:22:13 middleware.py[line:48]/INFO/  Enabled item pipelines:
['urlScrapy.pipelines.UrlscrapyPipeline']
2019-Jun-09 18:22:13 engine.py[line:256]/INFO/  Spider opened
2019-Jun-09 18:22:13 logstats.py[line:48]/INFO/  Crawled 0 pages (at 0 pages/min), scraped 0 items (at 0 items/min)
2019-Jun-09 18:22:13 telnet.py[line:74]/INFO/  Telnet console listening on 127.0.0.1:6023
2019-Jun-09 18:22:13 middlewares.py[line:19]/DEBUG/  =====  ProxyMiddleware get a random_proxy:【 http://120.83.111.234:9999 】 =====
2019-Jun-09 18:22:19 retry.py[line:75]/DEBUG/  Retrying <GET http://www.alexa.cn/robots.txt> (failed 1 times): Connection was refused by other side: 10061: 由于目标计算机积极拒绝，无法连接。.
2019-Jun-09 18:22:19 middlewares.py[line:19]/DEBUG/  =====  ProxyMiddleware get a random_proxy:【 http://182.111.129.37:53281 】 =====
2019-Jun-09 18:22:41 retry.py[line:75]/DEBUG/  Retrying <GET http://www.alexa.cn/robots.txt> (failed 2 times): TCP connection timed out: 10060: 由于连接方在一段时间后没有正确答复或连接的主机没有反应，连接尝试失败。.
2019-Jun-09 18:22:41 middlewares.py[line:19]/DEBUG/  =====  ProxyMiddleware get a random_proxy:【 http://58.240.143.105:8118 】 =====
2019-Jun-09 18:23:02 retry.py[line:91]/DEBUG/  Gave up retrying <GET http://www.alexa.cn/robots.txt> (failed 3 times): TCP connection timed out: 10060: 由于连接方在一段时间后没有正确答复或连接的主机没有反应，连接尝试失败。.
2019-Jun-09 18:23:02 proxyDBManager.py[line:181]/DEBUG/  ===  success to update 58.240.143.105 proxy  ===
2019-Jun-09 18:23:02 proxyDBManager.py[line:181]/DEBUG/  ===  success to update 58.240.143.105 proxy  ===
2019-Jun-09 18:23:02 robotstxt.py[line:85]/ERROR/  Error downloading <GET http://www.alexa.cn/robots.txt>: TCP connection timed out: 10060: 由于连接方在一段时间后没有正确答复或连接的主机没有反应，连接尝试失败。.
Traceback (most recent call last):
  File "E:\Users\JohnParker\Anaconda3\lib\site-packages\scrapy\core\downloader\middleware.py", line 43, in process_request
    defer.returnValue((yield download_func(request=request,spider=spider)))
twisted.internet.error.TCPTimedOutError: TCP connection timed out: 10060: 由于连接方在一段时间后没有正确答复或连接的主机没有反应，连接尝试失败。.
2019-Jun-09 18:23:02 middlewares.py[line:19]/DEBUG/  =====  ProxyMiddleware get a random_proxy:【 http://163.204.245.252:9999 】 =====
2019-Jun-09 18:23:13 logstats.py[line:48]/INFO/  Crawled 0 pages (at 0 pages/min), scraped 0 items (at 0 items/min)
2019-Jun-09 18:23:23 retry.py[line:75]/DEBUG/  Retrying <GET http://www.alexa.cn/siterank/> (failed 1 times): TCP connection timed out: 10060: 由于连接方在一段时间后没有正确答复或连接的主机没有反应，连接尝试失败。.
2019-Jun-09 18:23:23 middlewares.py[line:19]/DEBUG/  =====  ProxyMiddleware get a random_proxy:【 http://112.87.70.109:9999 】 =====
2019-Jun-09 18:23:23 engine.py[line:238]/DEBUG/  Crawled (200) <GET http://www.alexa.cn/siterank/> (referer: http://www.alexa.cn/siterank/)
2019-Jun-09 18:23:23 middlewares.py[line:19]/DEBUG/  =====  ProxyMiddleware get a random_proxy:【 http://112.87.70.161:9999 】 =====
2019-Jun-09 18:23:23 middlewares.py[line:19]/DEBUG/  =====  ProxyMiddleware get a random_proxy:【 http://121.204.150.97:8118 】 =====
2019-Jun-09 18:23:23 middlewares.py[line:19]/DEBUG/  =====  ProxyMiddleware get a random_proxy:【 http://61.183.233.6:54896 】 =====
2019-Jun-09 18:23:23 middlewares.py[line:19]/DEBUG/  =====  ProxyMiddleware get a random_proxy:【 http://117.90.1.104:9999 】 =====
2019-Jun-09 18:23:23 middlewares.py[line:19]/DEBUG/  =====  ProxyMiddleware get a random_proxy:【 http://122.193.245.173:9999 】 =====
2019-Jun-09 18:23:23 middlewares.py[line:19]/DEBUG/  =====  ProxyMiddleware get a random_proxy:【 http://119.176.170.123:9999 】 =====
2019-Jun-09 18:23:23 middlewares.py[line:19]/DEBUG/  =====  ProxyMiddleware get a random_proxy:【 http://221.7.255.168:8080 】 =====
2019-Jun-09 18:23:23 middlewares.py[line:19]/DEBUG/  =====  ProxyMiddleware get a random_proxy:【 http://121.233.251.235:9999 】 =====
2019-Jun-09 18:23:23 middlewares.py[line:19]/DEBUG/  =====  ProxyMiddleware get a random_proxy:【 http://114.228.77.213:9999 】 =====
2019-Jun-09 18:23:23 middlewares.py[line:19]/DEBUG/  =====  ProxyMiddleware get a random_proxy:【 http://112.85.166.122:9999 】 =====
2019-Jun-09 18:23:36 retry.py[line:75]/DEBUG/  Retrying <GET http://www.alexa.cn/Babytree.com> (failed 1 times): 503 Service Unavailable
2019-Jun-09 18:23:36 middlewares.py[line:19]/DEBUG/  =====  ProxyMiddleware get a random_proxy:【 http://112.85.149.139:9999 】 =====
2019-Jun-09 18:23:45 engine.py[line:238]/DEBUG/  Crawled (200) <GET http://www.alexa.cn/Zhihu.com> (referer: http://www.alexa.cn/siterank/)
2019-Jun-09 18:23:45 middlewares.py[line:19]/DEBUG/  =====  ProxyMiddleware get a random_proxy:【 http://112.87.70.161:9999 】 =====
2019-Jun-09 18:23:45 connectionpool.py[line:205]/DEBUG/  Starting new HTTP connection (1): 127.0.0.1:1081
2019-Jun-09 18:23:45 connectionpool.py[line:393]/DEBUG/  http://127.0.0.1:1081 "GET http://www.alexa.cn/api/icp/info?token=b1725180-J18lsl-CEmz3rbaXpFQcLVwNocnlz4ZNVCi7P6vZcq1tqzfhUwBGCptg-N&url=Zhihu.com&host=&vcode= HTTP/1.1" 200 None
2019-Jun-09 18:23:45 connectionpool.py[line:205]/DEBUG/  Starting new HTTP connection (1): 127.0.0.1:1081
2019-Jun-09 18:23:45 connectionpool.py[line:393]/DEBUG/  http://127.0.0.1:1081 "GET http://www.alexa.cn/api/server/get?token=a8031b4enD7bXe1VdOR4nUkrCk6QO7QVWvkRkj1BsUEZV3sbmE04SdOm6SfTW-J4-N&url=Zhihu.com&force_update=0 HTTP/1.1" 200 None
2019-Jun-09 18:23:45 connectionpool.py[line:205]/DEBUG/  Starting new HTTP connection (1): 127.0.0.1:1081
2019-Jun-09 18:23:45 connectionpool.py[line:393]/DEBUG/  http://127.0.0.1:1081 "GET http://www.alexa.cn/api/who_is/get?token=f5e06a5bAt65qoafZ2R7giPfZRHn9P0fKWlIxgXBlo3Hc94yPvsu7UlIMhYpFDI-M&url=Zhihu.com&force_update=0 HTTP/1.1" 200 None
2019-Jun-09 18:23:45 connectionpool.py[line:205]/DEBUG/  Starting new HTTP connection (1): 127.0.0.1:1081
2019-Jun-09 18:23:46 connectionpool.py[line:393]/DEBUG/  http://127.0.0.1:1081 "GET http://www.alexa.cn/api/alexa/free?token=f942e3068OIWSOer-EnwKVZ8NISJCekzauHjvHqVhstZAXvMkMRAuXRSdT4Blp6E-M&url=Zhihu.com HTTP/1.1" 200 None
2019-Jun-09 18:23:46 scraper.py[line:240]/DEBUG/  Scraped from <200 http://www.alexa.cn/Zhihu.com>
{'com_name': '北京智者天下科技有限公司',
 'content_type': 'Content-Type: text/html',
 'country_code': 'CN',
 'country_rank': '25',
 'create_day': '2007-06-16',
 'domain': 'zhihu.com',
 'http_type': 'HTTP/1.1 301 Moved Permanently',
 'icp_no': '京ICP备13052560号-1',
 'icp_type': '企业',
 'nserver': 'NS3.DNSV5.COM',
 'rank_trend_chart': 'http://traffic.alexa.com/graph?o=lt&y=q&b=ffffff&n=666666&f=999999&p=4e8cff&r=1y&t=2&z=0&c=1&h=150&w=340&u=qq.comZhihu.com',
 'reg_server': 'GODADDY.COM, LLC',
 'search_proportion_chart': 'http://traffic.alexa.com/graph?y=t&b=ffffff&n=666&f=999999&r=7d&t=2&z=30&c=1&h=280&w=920&u=Zhihu.com',
 'server': 'WHOIS.GODADDY.COM',
 'server_ip': '118.89.204.190',
 'server_location': '天津市滨海新区',
 'server_type': 'ZWS',
 'web_home': 'www.zhihu.com',
 'web_name': '知乎',
 'world_rank': '82',
 'world_uv_rank': '81'}
2019-Jun-09 18:23:50 retry.py[line:75]/DEBUG/  Retrying <GET http://www.alexa.cn/siterank/2> (failed 1 times): TCP connection timed out: 10060: 由于连接方在一段时间后没有正确答复或连接的主机没有反应，连接尝试失败。.
2019-Jun-09 18:23:50 middlewares.py[line:19]/DEBUG/  =====  ProxyMiddleware get a random_proxy:【 http://112.85.166.122:9999 】 =====
2019-Jun-09 18:24:05 engine.py[line:238]/DEBUG/  Crawled (200) <GET http://www.alexa.cn/Xinhuanet.com> (referer: http://www.alexa.cn/siterank/)
2019-Jun-09 18:24:05 middlewares.py[line:19]/DEBUG/  =====  ProxyMiddleware get a random_proxy:【 http://122.193.244.243:9999 】 =====
2019-Jun-09 18:24:05 connectionpool.py[line:205]/DEBUG/  Starting new HTTP connection (1): 127.0.0.1:1081
2019-Jun-09 18:24:05 connectionpool.py[line:393]/DEBUG/  http://127.0.0.1:1081 "GET http://www.alexa.cn/api/icp/info?token=177784d0YUgeWKC3usFLGHGF-HuZ6pb2atoCvo-EJp5pQi0njQKhsjy-EelGIhi8Wo-M&url=Xinhuanet.com&host=&vcode= HTTP/1.1" 200 None
2019-Jun-09 18:24:05 connectionpool.py[line:205]/DEBUG/  Starting new HTTP connection (1): 127.0.0.1:1081
2019-Jun-09 18:24:05 connectionpool.py[line:393]/DEBUG/  http://127.0.0.1:1081 "GET http://www.alexa.cn/api/server/get?token=cc024b78CbsJwm0UGHh78tcR9p3wnjiJq-FGNI9oW2w6wua9PkMq7gEmAXlH6qg4-K&url=Xinhuanet.com&force_update=0 HTTP/1.1" 200 None
2019-Jun-09 18:24:05 connectionpool.py[line:205]/DEBUG/  Starting new HTTP connection (1): 127.0.0.1:1081
2019-Jun-09 18:24:06 connectionpool.py[line:393]/DEBUG/  http://127.0.0.1:1081 "GET http://www.alexa.cn/api/who_is/get?token=e34c78cfdedCuEkOfSuukBgKeiqh8jBfzK7uFEtHlSc0odmozXgqooXQta7RN08-K&url=Xinhuanet.com&force_update=0 HTTP/1.1" 200 None
2019-Jun-09 18:24:06 connectionpool.py[line:205]/DEBUG/  Starting new HTTP connection (1): 127.0.0.1:1081
2019-Jun-09 18:24:06 connectionpool.py[line:393]/DEBUG/  http://127.0.0.1:1081 "GET http://www.alexa.cn/api/alexa/free?token=e98faaff3DvEF65TaVInFoyBq6ZwNb14DOaHvgZXwCF-Hf534nE7ifdGz-HI5gCz8-O&url=Xinhuanet.com HTTP/1.1" 200 None
2019-Jun-09 18:24:06 scraper.py[line:240]/DEBUG/  Scraped from <200 http://www.alexa.cn/Xinhuanet.com>
{'com_name': '新华网股份有限公司',
 'content_type': 'Content-Type: text/html',
 'country_code': 'CN',
 'country_rank': '21',
 'create_day': '2000-04-28',
 'domain': 'xinhuanet.com',
 'http_type': 'HTTP/1.1 200 OK',
 'icp_no': '京ICP证010042号-2',
 'icp_type': '企业',
 'nserver': 'NS1.CDNS.CN',
 'rank_trend_chart': 'http://traffic.alexa.com/graph?o=lt&y=q&b=ffffff&n=666666&f=999999&p=4e8cff&r=1y&t=2&z=0&c=1&h=150&w=340&u=qq.comXinhuanet.com',
 'reg_server': 'BEIJING SANFRONT INFORMATION TECHNOLOGY CO., LTD',
 'search_proportion_chart': 'http://traffic.alexa.com/graph?y=t&b=ffffff&n=666&f=999999&r=7d&t=2&z=30&c=1&h=280&w=920&u=Xinhuanet.com',
 'server': 'WHOIS.SFN.CN',
 'server_ip': '183.131.127.122',
 'server_location': '浙江省台州市',
 'server_type': 'nginx',
 'web_home': 'www.xinhuanet.com',
 'web_name': '新华网',
 'world_rank': '67',
 'world_uv_rank': '77'}
2019-Jun-09 18:24:10 retry.py[line:75]/DEBUG/  Retrying <GET http://www.alexa.cn/Cnblogs.com> (failed 1 times): TCP connection timed out: 10060: 由于连接方在一段时间后没有正确答复或连接的主机没有反应，连接尝试失败。.
2019-Jun-09 18:24:10 middlewares.py[line:19]/DEBUG/  =====  ProxyMiddleware get a random_proxy:【 http://119.176.170.123:9999 】 =====
2019-Jun-09 18:24:13 logstats.py[line:48]/INFO/  Crawled 3 pages (at 3 pages/min), scraped 2 items (at 2 items/min)
2019-Jun-09 18:24:15 retry.py[line:75]/DEBUG/  Retrying <GET http://www.alexa.cn/Hao123.com> (failed 1 times): TCP connection timed out: 10060: 由于连接方在一段时间后没有正确答复或连接的主机没有反应，连接尝试失败。.
2019-Jun-09 18:24:15 middlewares.py[line:19]/DEBUG/  =====  ProxyMiddleware get a random_proxy:【 http://117.90.1.104:9999 】 =====
2019-Jun-09 18:24:17 retry.py[line:75]/DEBUG/  Retrying <GET http://www.alexa.cn/163.com> (failed 1 times): Connection was refused by other side: 10061: 由于目标计算机积极拒绝，无法连接。.
2019-Jun-09 18:24:17 middlewares.py[line:19]/DEBUG/  =====  ProxyMiddleware get a random_proxy:【 http://117.90.3.74:9000 】 =====
2019-Jun-09 18:24:19 retry.py[line:75]/DEBUG/  Retrying <GET http://www.alexa.cn/Soso.com> (failed 1 times): TCP connection timed out: 10060: 由于连接方在一段时间后没有正确答复或连接的主机没有反应，连接尝试失败。.
2019-Jun-09 18:24:19 middlewares.py[line:19]/DEBUG/  =====  ProxyMiddleware get a random_proxy:【 http://163.204.242.149:9999 】 =====
2019-Jun-09 18:24:37 retry.py[line:75]/DEBUG/  Retrying <GET http://www.alexa.cn/Bilibili.com> (failed 1 times): TCP connection timed out: 10060: 由于连接方在一段时间后没有正确答复或连接的主机没有反应，连接尝试失败。.
2019-Jun-09 18:24:37 middlewares.py[line:19]/DEBUG/  =====  ProxyMiddleware get a random_proxy:【 http://115.28.148.192:8118 】 =====
2019-Jun-09 18:24:44 retry.py[line:75]/DEBUG/  Retrying <GET http://www.alexa.cn/Gmw.cn> (failed 1 times): TCP connection timed out: 10060: 由于连接方在一段时间后没有正确答复或连接的主机没有反应，连接尝试失败。.
2019-Jun-09 18:24:44 middlewares.py[line:19]/DEBUG/  =====  ProxyMiddleware get a random_proxy:【 http://60.13.42.8:9999 】 =====
2019-Jun-09 18:24:51 retry.py[line:75]/DEBUG/  Retrying <GET http://www.alexa.cn/Alipay.com> (failed 1 times): TCP connection timed out: 10060: 由于连接方在一段时间后没有正确答复或连接的主机没有反应，连接尝试失败。.
2019-Jun-09 18:24:51 middlewares.py[line:19]/DEBUG/  =====  ProxyMiddleware get a random_proxy:【 http://121.233.251.235:9999 】 =====
2019-Jun-09 18:24:58 retry.py[line:75]/DEBUG/  Retrying <GET http://www.alexa.cn/Csdn.net> (failed 1 times): TCP connection timed out: 10060: 由于连接方在一段时间后没有正确答复或连接的主机没有反应，连接尝试失败。.
2019-Jun-09 18:24:58 middlewares.py[line:19]/DEBUG/  =====  ProxyMiddleware get a random_proxy:【 http://117.93.135.211:53281 】 =====
2019-Jun-09 18:25:04 retry.py[line:75]/DEBUG/  Retrying <GET http://www.alexa.cn/360.cn> (failed 1 times): TCP connection timed out: 10060: 由于连接方在一段时间后没有正确答复或连接的主机没有反应，连接尝试失败。.
2019-Jun-09 18:25:04 middlewares.py[line:19]/DEBUG/  =====  ProxyMiddleware get a random_proxy:【 http://61.183.233.6:54896 】 =====
2019-Jun-09 18:25:10 retry.py[line:75]/DEBUG/  Retrying <GET http://www.alexa.cn/Weibo.com> (failed 1 times): TCP connection timed out: 10060: 由于连接方在一段时间后没有正确答复或连接的主机没有反应，连接尝试失败。.
2019-Jun-09 18:25:10 middlewares.py[line:19]/DEBUG/  =====  ProxyMiddleware get a random_proxy:【 http://121.204.150.97:8118 】 =====
2019-Jun-09 18:25:13 logstats.py[line:48]/INFO/  Crawled 3 pages (at 0 pages/min), scraped 2 items (at 0 items/min)
2019-Jun-09 18:25:17 retry.py[line:75]/DEBUG/  Retrying <GET http://www.alexa.cn/Sina.com.cn> (failed 1 times): TCP connection timed out: 10060: 由于连接方在一段时间后没有正确答复或连接的主机没有反应，连接尝试失败。.
2019-Jun-09 18:25:17 middlewares.py[line:19]/DEBUG/  =====  ProxyMiddleware get a random_proxy:【 http://1.192.240.238:9999 】 =====
2019-Jun-09 18:25:22 retry.py[line:75]/DEBUG/  Retrying <GET http://www.alexa.cn/Taobao.com> (failed 1 times): [<twisted.python.failure.Failure twisted.internet.error.ConnectionLost: Connection to the other side was lost in a non-clean fashion.>]
2019-Jun-09 18:25:22 middlewares.py[line:19]/DEBUG/  =====  ProxyMiddleware get a random_proxy:【 http://112.85.166.245:9999 】 =====
2019-Jun-09 18:25:24 retry.py[line:75]/DEBUG/  Retrying <GET http://www.alexa.cn/Jd.com> (failed 1 times): TCP connection timed out: 10060: 由于连接方在一段时间后没有正确答复或连接的主机没有反应，连接尝试失败。.
2019-Jun-09 18:25:24 middlewares.py[line:19]/DEBUG/  =====  ProxyMiddleware get a random_proxy:【 http://58.240.143.105:8118 】 =====
2019-Jun-09 18:25:31 retry.py[line:75]/DEBUG/  Retrying <GET http://www.alexa.cn/Sohu.com> (failed 1 times): TCP connection timed out: 10060: 由于连接方在一段时间后没有正确答复或连接的主机没有反应，连接尝试失败。.
2019-Jun-09 18:25:31 middlewares.py[line:19]/DEBUG/  =====  ProxyMiddleware get a random_proxy:【 http://1.197.203.44:9999 】 =====
2019-Jun-09 18:25:31 engine.py[line:238]/DEBUG/  Crawled (200) <GET http://www.alexa.cn/Qq.com> (referer: http://www.alexa.cn/siterank/)
2019-Jun-09 18:25:31 middlewares.py[line:19]/DEBUG/  =====  ProxyMiddleware get a random_proxy:【 http://112.87.70.109:9999 】 =====
2019-Jun-09 18:25:31 connectionpool.py[line:205]/DEBUG/  Starting new HTTP connection (1): 127.0.0.1:1081
2019-Jun-09 18:25:31 connectionpool.py[line:393]/DEBUG/  http://127.0.0.1:1081 "GET http://www.alexa.cn/api/icp/info?token=74e5b8f1NqDyG3E0bvIRj3otXhnaFjaLGb4tlNh5GffzOYQyKFm7l-HSeY7Bv9EI-O&url=Qq.com&host=&vcode= HTTP/1.1" 200 None
2019-Jun-09 18:25:31 connectionpool.py[line:205]/DEBUG/  Starting new HTTP connection (1): 127.0.0.1:1081
2019-Jun-09 18:25:32 connectionpool.py[line:393]/DEBUG/  http://127.0.0.1:1081 "GET http://www.alexa.cn/api/server/get?token=2756c323GXFCpEn1HrL06ek-GH7YKkEH020jM4bQBDHqOeW0BHtqLq1eyTJRTNAA-M&url=Qq.com&force_update=0 HTTP/1.1" 200 None
2019-Jun-09 18:25:32 connectionpool.py[line:205]/DEBUG/  Starting new HTTP connection (1): 127.0.0.1:1081
2019-Jun-09 18:25:32 connectionpool.py[line:393]/DEBUG/  http://127.0.0.1:1081 "GET http://www.alexa.cn/api/who_is/get?token=6e6d677b5AS8j1-AG1cBcDILyAyXAxaTBhKHPJopsrSAYgi5HjQnGHdKz7Dfr1gI-O&url=Qq.com&force_update=0 HTTP/1.1" 200 None
2019-Jun-09 18:25:32 connectionpool.py[line:205]/DEBUG/  Starting new HTTP connection (1): 127.0.0.1:1081
2019-Jun-09 18:25:32 connectionpool.py[line:393]/DEBUG/  http://127.0.0.1:1081 "GET http://www.alexa.cn/api/alexa/free?token=be1332cfFKjZeUo5nP3JtotAdyc-IXNgwDhS1KthRQuEBikesIHSfYWBtmkRNwcI-K&url=Qq.com HTTP/1.1" 200 None
2019-Jun-09 18:25:32 scraper.py[line:240]/DEBUG/  Scraped from <200 http://www.alexa.cn/Qq.com>
{'com_name': '深圳市腾讯计算机系统有限公司',
 'content_type': 'Content-Type: text/html',
 'country_code': 'CN',
 'country_rank': '2',
 'create_day': '1995-05-04',
 'domain': 'qq.com',
 'http_type': 'HTTP/1.1 302 Moved Temporarily',
 'icp_no': '粤B2-20090059-5',
 'icp_type': '企业',
 'nserver': 'NS1.QQ.COM',
 'rank_trend_chart': 'http://traffic.alexa.com/graph?o=lt&y=q&b=ffffff&n=666666&f=999999&p=4e8cff&r=1y&t=2&z=0&c=1&h=150&w=340&u=qq.comQq.com',
 'reg_server': 'MARKMONITOR INC.',
 'search_proportion_chart': 'http://traffic.alexa.com/graph?y=t&b=ffffff&n=666&f=999999&r=7d&t=2&z=30&c=1&h=280&w=920&u=Qq.com',
 'server': 'WHOIS.MARKMONITOR.COM',
 'server_ip': '58.250.137.36',
 'server_location': '广东省深圳市',
 'server_type': 'stgw/1.3.10.6_1.13.5',
 'web_home': 'www.qq.com',
 'web_name': '腾讯网',
 'world_rank': '6',
 'world_uv_rank': '6'}
2019-Jun-09 18:25:38 retry.py[line:75]/DEBUG/  Retrying <GET http://www.alexa.cn/Tmall.com> (failed 1 times): TCP connection timed out: 10060: 由于连接方在一段时间后没有正确答复或连接的主机没有反应，连接尝试失败。.
2019-Jun-09 18:25:38 middlewares.py[line:19]/DEBUG/  =====  ProxyMiddleware get a random_proxy:【 http://112.87.69.254:9999 】 =====
2019-Jun-09 18:25:43 retry.py[line:75]/DEBUG/  Retrying <GET http://www.alexa.cn/Baidu.com> (failed 1 times): Connection was refused by other side: 10061: 由于目标计算机积极拒绝，无法连接。.
2019-Jun-09 18:25:43 middlewares.py[line:19]/DEBUG/  =====  ProxyMiddleware get a random_proxy:【 http://112.87.69.254:9999 】 =====
2019-Jun-09 18:25:48 retry.py[line:75]/DEBUG/  Retrying <GET http://www.alexa.cn/Csdn.net> (failed 2 times): Connection was refused by other side: 10061: 由于目标计算机积极拒绝，无法连接。.
2019-Jun-09 18:25:48 middlewares.py[line:19]/DEBUG/  =====  ProxyMiddleware get a random_proxy:【 http://114.228.77.213:9999 】 =====
2019-Jun-09 18:25:54 retry.py[line:75]/DEBUG/  Retrying <GET http://www.alexa.cn/Weibo.com> (failed 2 times): [<twisted.python.failure.Failure twisted.internet.error.ConnectionLost: Connection to the other side was lost in a non-clean fashion.>]
2019-Jun-09 18:25:54 middlewares.py[line:19]/DEBUG/  =====  ProxyMiddleware get a random_proxy:【 http://115.28.148.192:8118 】 =====
2019-Jun-09 18:26:09 retry.py[line:75]/DEBUG/  Retrying <GET http://www.alexa.cn/360.cn> (failed 2 times): TCP connection timed out: 10060: 由于连接方在一段时间后没有正确答复或连接的主机没有反应，连接尝试失败。.
2019-Jun-09 18:26:09 middlewares.py[line:19]/DEBUG/  =====  ProxyMiddleware get a random_proxy:【 http://122.193.244.243:9999 】 =====
2019-Jun-09 18:26:13 logstats.py[line:48]/INFO/  Crawled 4 pages (at 1 pages/min), scraped 3 items (at 1 items/min)
2019-Jun-09 18:26:21 retry.py[line:75]/DEBUG/  Retrying <GET http://www.alexa.cn/Sina.com.cn> (failed 2 times): TCP connection timed out: 10060: 由于连接方在一段时间后没有正确答复或连接的主机没有反应，连接尝试失败。.
2019-Jun-09 18:26:21 middlewares.py[line:19]/DEBUG/  =====  ProxyMiddleware get a random_proxy:【 http://218.73.132.222:9999 】 =====
2019-Jun-09 18:26:22 retry.py[line:75]/DEBUG/  Retrying <GET http://www.alexa.cn/Jd.com> (failed 2 times): Connection was refused by other side: 10061: 由于目标计算机积极拒绝，无法连接。.
2019-Jun-09 18:26:22 middlewares.py[line:19]/DEBUG/  =====  ProxyMiddleware get a random_proxy:【 http://115.28.148.192:8118 】 =====
2019-Jun-09 18:26:27 engine.py[line:238]/DEBUG/  Crawled (200) <GET http://www.alexa.cn/Alipay.com> (referer: http://www.alexa.cn/siterank/)
2019-Jun-09 18:26:27 middlewares.py[line:19]/DEBUG/  =====  ProxyMiddleware get a random_proxy:【 http://222.189.144.240:9999 】 =====
2019-Jun-09 18:26:27 connectionpool.py[line:205]/DEBUG/  Starting new HTTP connection (1): 127.0.0.1:1081
2019-Jun-09 18:26:27 connectionpool.py[line:393]/DEBUG/  http://127.0.0.1:1081 "GET http://www.alexa.cn/api/icp/info?token=0ab694a7fIjgnSX3BNDFs6hJqepGSkwR-E5C3KPiKJyP08yp2j4fxNwMwmuYy664-K&url=Alipay.com&host=&vcode= HTTP/1.1" 200 None
2019-Jun-09 18:26:27 connectionpool.py[line:205]/DEBUG/  Starting new HTTP connection (1): 127.0.0.1:1081
2019-Jun-09 18:26:28 connectionpool.py[line:393]/DEBUG/  http://127.0.0.1:1081 "GET http://www.alexa.cn/api/server/get?token=b783ace4UiHlLNgb4gPZlBObTOONAys5YM7WXW0LorD8ZM0K6YShN3UMHILOVfY-M&url=Alipay.com&force_update=0 HTTP/1.1" 200 None
2019-Jun-09 18:26:28 connectionpool.py[line:205]/DEBUG/  Starting new HTTP connection (1): 127.0.0.1:1081
2019-Jun-09 18:26:28 connectionpool.py[line:393]/DEBUG/  http://127.0.0.1:1081 "GET http://www.alexa.cn/api/who_is/get?token=72c1d9f1xvrk9fGn748Hvjzv4E9-DWCdmy120JE-DhZM4IQfjFLM5UtJ54NCSsd40-K&url=Alipay.com&force_update=0 HTTP/1.1" 200 None
2019-Jun-09 18:26:28 connectionpool.py[line:205]/DEBUG/  Starting new HTTP connection (1): 127.0.0.1:1081
2019-Jun-09 18:26:28 connectionpool.py[line:393]/DEBUG/  http://127.0.0.1:1081 "GET http://www.alexa.cn/api/alexa/free?token=c8a62cb9WJPkHfPelt2uOO4cHbh4LSBUW4c0PNj-ERBW4kX0riAUv9KsoKdgliXE-K&url=Alipay.com HTTP/1.1" 200 None
2019-Jun-09 18:26:28 scraper.py[line:240]/DEBUG/  Scraped from <200 http://www.alexa.cn/Alipay.com>
{'com_name': '支付宝（中国）网络技术有限公司',
 'content_type': 'Content-Type: text/html',
 'country_code': 'CN',
 'country_rank': '15',
 'create_day': '2004-10-08',
 'domain': 'alipay.com',
 'http_type': 'HTTP/1.1 301 Moved Permanently',
 'icp_no': '沪ICP备15027489号-2',
 'icp_type': '企业',
 'nserver': 'NS1.ALIPAY.COM',
 'rank_trend_chart': 'http://traffic.alexa.com/graph?o=lt&y=q&b=ffffff&n=666666&f=999999&p=4e8cff&r=1y&t=2&z=0&c=1&h=150&w=340&u=qq.comAlipay.com',
 'reg_server': 'ALIBABA CLOUD COMPUTING (BEIJING) CO., LTD.',
 'search_proportion_chart': 'http://traffic.alexa.com/graph?y=t&b=ffffff&n=666&f=999999&r=7d&t=2&z=30&c=1&h=280&w=920&u=Alipay.com',
 'server': 'GRS-WHOIS.HICHINA.COM',
 'server_ip': '110.75.231.7',
 'server_location': '浙江省杭州市',
 'server_type': 'Tengine/2.1.0',
 'web_home': 'www.alipay.com',
 'web_name': '新支付宝',
 'world_rank': '34',
 'world_uv_rank': '36'}
2019-Jun-09 18:26:28 retry.py[line:75]/DEBUG/  Retrying <GET http://www.alexa.cn/Taobao.com> (failed 2 times): TCP connection timed out: 10060: 由于连接方在一段时间后没有正确答复或连接的主机没有反应，连接尝试失败。.
2019-Jun-09 18:26:28 middlewares.py[line:19]/DEBUG/  =====  ProxyMiddleware get a random_proxy:【 http://1.197.203.44:9999 】 =====
2019-Jun-09 18:26:34 engine.py[line:238]/DEBUG/  Crawled (200) <GET http://www.alexa.cn/Tmall.com> (referer: http://www.alexa.cn/siterank/)
2019-Jun-09 18:26:34 middlewares.py[line:19]/DEBUG/  =====  ProxyMiddleware get a random_proxy:【 http://59.44.247.194:9797 】 =====
2019-Jun-09 18:26:34 connectionpool.py[line:205]/DEBUG/  Starting new HTTP connection (1): 127.0.0.1:1081
2019-Jun-09 18:26:34 connectionpool.py[line:393]/DEBUG/  http://127.0.0.1:1081 "GET http://www.alexa.cn/api/icp/info?token=7583852dS6-Amq3926Gg7f-GKb9FCc09LosJzKlxUxpAnoraSxr5jRam8OFxwCZ6Y-L&url=Tmall.com&host=&vcode= HTTP/1.1" 200 None
2019-Jun-09 18:26:34 connectionpool.py[line:205]/DEBUG/  Starting new HTTP connection (1): 127.0.0.1:1081
2019-Jun-09 18:26:34 connectionpool.py[line:393]/DEBUG/  http://127.0.0.1:1081 "GET http://www.alexa.cn/api/server/get?token=bdc6b70eUteTGqb6ZZ-DfINnR0JyAOoOiEm6uyirt1PvrgZ4QB2gX5U-ILBzjrYxg-L&url=Tmall.com&force_update=0 HTTP/1.1" 200 None
2019-Jun-09 18:26:34 connectionpool.py[line:205]/DEBUG/  Starting new HTTP connection (1): 127.0.0.1:1081
2019-Jun-09 18:26:34 connectionpool.py[line:393]/DEBUG/  http://127.0.0.1:1081 "GET http://www.alexa.cn/api/who_is/get?token=3191e6bbOy25nUxnq7cHnS0ChcZDbK5ipdfifFRMGdgRm6ugTQygJ859SqfcDVc-M&url=Tmall.com&force_update=0 HTTP/1.1" 200 None
2019-Jun-09 18:26:34 connectionpool.py[line:205]/DEBUG/  Starting new HTTP connection (1): 127.0.0.1:1081
2019-Jun-09 18:26:34 connectionpool.py[line:393]/DEBUG/  http://127.0.0.1:1081 "GET http://www.alexa.cn/api/alexa/free?token=3653b15bq1UZpI3Z53-HdIG-HBn0vkTU-AhbXFFMFMTNpQyYoF906FEGesAEtXO7qU-M&url=Tmall.com HTTP/1.1" 200 None
2019-Jun-09 18:26:34 scraper.py[line:240]/DEBUG/  Scraped from <200 http://www.alexa.cn/Tmall.com>
{'com_name': '浙江天猫网络有限公司',
 'content_type': 'Content-Type: text/html',
 'country_code': 'CN',
 'country_rank': '4',
 'create_day': '1997-10-17',
 'domain': 'tmall.com',
 'http_type': 'HTTP/1.1 302 Found',
 'icp_no': '浙B2-20110446-1',
 'icp_type': '企业',
 'nserver': 'NS4.TAOBAO.COM',
 'rank_trend_chart': 'http://traffic.alexa.com/graph?o=lt&y=q&b=ffffff&n=666666&f=999999&p=4e8cff&r=1y&t=2&z=0&c=1&h=150&w=340&u=qq.comTmall.com',
 'reg_server': 'ALIBABA CLOUD COMPUTING (BEIJING) CO., LTD.',
 'search_proportion_chart': 'http://traffic.alexa.com/graph?y=t&b=ffffff&n=666&f=999999&r=7d&t=2&z=30&c=1&h=280&w=920&u=Tmall.com',
 'server': 'GRS-WHOIS.HICHINA.COM',
 'server_ip': '101.37.183.170',
 'server_location': '浙江省杭州市',
 'server_type': 'Tengine',
 'web_home': 'www.tmall.com',
 'web_name': '天猫',
 'world_rank': '8',
 'world_uv_rank': '7'}
2019-Jun-09 18:26:41 engine.py[line:238]/DEBUG/  Crawled (200) <GET http://www.alexa.cn/Baidu.com> (referer: http://www.alexa.cn/siterank/)
2019-Jun-09 18:26:41 middlewares.py[line:19]/DEBUG/  =====  ProxyMiddleware get a random_proxy:【 http://163.204.245.252:9999 】 =====
2019-Jun-09 18:26:41 connectionpool.py[line:205]/DEBUG/  Starting new HTTP connection (1): 127.0.0.1:1081
2019-Jun-09 18:26:41 connectionpool.py[line:393]/DEBUG/  http://127.0.0.1:1081 "GET http://www.alexa.cn/api/icp/info?token=3df72b98b9nBkPGdul7KovJEmOXSrPvfeahCBJftoRun1Qxe9nmjTgSSq1H-BjxU-N&url=Baidu.com&host=&vcode= HTTP/1.1" 200 None
2019-Jun-09 18:26:41 connectionpool.py[line:205]/DEBUG/  Starting new HTTP connection (1): 127.0.0.1:1081
2019-Jun-09 18:26:42 connectionpool.py[line:393]/DEBUG/  http://127.0.0.1:1081 "GET http://www.alexa.cn/api/server/get?token=0f2c3603hXACFK3ZUcE7SmjR90JoS4JG6o4ngiW0Huiamkf-E0wbti1RATIvVH2M-K&url=Baidu.com&force_update=0 HTTP/1.1" 200 None
2019-Jun-09 18:26:42 connectionpool.py[line:205]/DEBUG/  Starting new HTTP connection (1): 127.0.0.1:1081
2019-Jun-09 18:26:42 connectionpool.py[line:393]/DEBUG/  http://127.0.0.1:1081 "GET http://www.alexa.cn/api/who_is/get?token=670e10f0-DoTOeXUNXxkle7BLsvEpmTn6xHYATJrSLDiMazvZHKpnzgQbkKRGqno-N&url=Baidu.com&force_update=0 HTTP/1.1" 200 None
2019-Jun-09 18:26:42 connectionpool.py[line:205]/DEBUG/  Starting new HTTP connection (1): 127.0.0.1:1081
2019-Jun-09 18:26:42 connectionpool.py[line:393]/DEBUG/  http://127.0.0.1:1081 "GET http://www.alexa.cn/api/alexa/free?token=75c8bd362DsvQqf5RUBy3O8MT4qldjNKwrFI7LuSVKSjUNcK1a-FzY8SNSggl-Fv8-L&url=Baidu.com HTTP/1.1" 200 None
2019-Jun-09 18:26:42 scraper.py[line:240]/DEBUG/  Scraped from <200 http://www.alexa.cn/Baidu.com>
{'com_name': '北京百度网讯科技有限公司',
 'content_type': 'Content-Type: text/html',
 'country_code': 'CN',
 'country_rank': '1',
 'create_day': '1999-10-11',
 'domain': 'baidu.com',
 'http_type': 'HTTP/1.1 200 OK',
 'icp_no': '京ICP证030173号-1',
 'icp_type': '企业',
 'nserver': 'NS1.BAIDU.COM',
 'rank_trend_chart': 'http://traffic.alexa.com/graph?o=lt&y=q&b=ffffff&n=666666&f=999999&p=4e8cff&r=1y&t=2&z=0&c=1&h=150&w=340&u=qq.comBaidu.com',
 'reg_server': 'MARKMONITOR INC.',
 'search_proportion_chart': 'http://traffic.alexa.com/graph?y=t&b=ffffff&n=666&f=999999&r=7d&t=2&z=30&c=1&h=280&w=920&u=Baidu.com',
 'server': 'WHOIS.MARKMONITOR.COM',
 'server_ip': '115.239.210.27',
 'server_location': '浙江省杭州市',
 'server_type': 'bfe/1.0.8.18',
 'web_home': 'www.baidu.com',
 'web_name': '百度',
 'world_rank': '4',
 'world_uv_rank': '4'}
2019-Jun-09 18:26:43 retry.py[line:75]/DEBUG/  Retrying <GET http://www.alexa.cn/Sohu.com> (failed 2 times): TCP connection timed out: 10060: 由于连接方在一段时间后没有正确答复或连接的主机没有反应，连接尝试失败。.
2019-Jun-09 18:26:43 middlewares.py[line:19]/DEBUG/  =====  ProxyMiddleware get a random_proxy:【 http://112.85.166.122:9999 】 =====
2019-Jun-09 18:27:07 retry.py[line:75]/DEBUG/  Retrying <GET http://www.alexa.cn/Gmw.cn> (failed 2 times): TCP connection timed out: 10060: 由于连接方在一段时间后没有正确答复或连接的主机没有反应，连接尝试失败。.
2019-Jun-09 18:27:07 middlewares.py[line:19]/DEBUG/  =====  ProxyMiddleware get a random_proxy:【 http://222.189.190.187:9999 】 =====
2019-Jun-09 18:27:07 retry.py[line:75]/DEBUG/  Retrying <GET http://www.alexa.cn/Hao123.com> (failed 2 times): 503 Service Unavailable
2019-Jun-09 18:27:07 middlewares.py[line:19]/DEBUG/  =====  ProxyMiddleware get a random_proxy:【 http://112.85.166.245:9999 】 =====
2019-Jun-09 18:27:11 base.py[line:940]/DEBUG/  Looking for jobs to run
2019-Jun-09 18:27:11 base.py[line:123]/INFO/  Running job "ProxyPoolWorker.__check_ip_availability_task (trigger: interval[0:05:00], next run at: 2019-06-09 18:27:11 CST)" (scheduled at 2019-06-09 18:27:11.952184+08:00)
2019-Jun-09 18:27:11 base.py[line:1020]/DEBUG/  Next wakeup is due at 2019-06-09 18:32:11.952184+08:00 (in 299.998371 seconds)
2019-Jun-09 18:27:11 base.py[line:144]/INFO/  Job "ProxyPoolWorker.__check_ip_availability_task (trigger: interval[0:05:00], next run at: 2019-06-09 18:32:11 CST)" executed successfully
2019-Jun-09 18:27:13 logstats.py[line:48]/INFO/  Crawled 7 pages (at 3 pages/min), scraped 6 items (at 3 items/min)
2019-Jun-09 18:27:18 retry.py[line:75]/DEBUG/  Retrying <GET http://www.alexa.cn/Soso.com> (failed 2 times): TCP connection timed out: 10060: 由于连接方在一段时间后没有正确答复或连接的主机没有反应，连接尝试失败。.
2019-Jun-09 18:27:18 middlewares.py[line:19]/DEBUG/  =====  ProxyMiddleware get a random_proxy:【 http://112.87.69.254:9999 】 =====
2019-Jun-09 18:27:22 retry.py[line:75]/DEBUG/  Retrying <GET http://www.alexa.cn/163.com> (failed 2 times): TCP connection timed out: 10060: 由于连接方在一段时间后没有正确答复或连接的主机没有反应，连接尝试失败。.
2019-Jun-09 18:27:22 middlewares.py[line:19]/DEBUG/  =====  ProxyMiddleware get a random_proxy:【 http://221.7.255.168:8080 】 =====
2019-Jun-09 18:27:24 retry.py[line:75]/DEBUG/  Retrying <GET http://www.alexa.cn/siterank/2> (failed 2 times): Connection was refused by other side: 10061: 由于目标计算机积极拒绝，无法连接。.
2019-Jun-09 18:27:24 middlewares.py[line:19]/DEBUG/  =====  ProxyMiddleware get a random_proxy:【 http://122.193.246.11:9999 】 =====
2019-Jun-09 18:27:26 engine.py[line:238]/DEBUG/  Crawled (200) <GET http://www.alexa.cn/Bilibili.com> (referer: http://www.alexa.cn/siterank/)
2019-Jun-09 18:27:26 middlewares.py[line:19]/DEBUG/  =====  ProxyMiddleware get a random_proxy:【 http://122.193.244.243:9999 】 =====
2019-Jun-09 18:27:27 connectionpool.py[line:205]/DEBUG/  Starting new HTTP connection (1): 127.0.0.1:1081
2019-Jun-09 18:27:27 connectionpool.py[line:393]/DEBUG/  http://127.0.0.1:1081 "GET http://www.alexa.cn/api/icp/info?token=d0f60c55XH6M7SkL0BPWjlrTLXf65sG-InsnfebVZUntjqnNA9C5ba4-ITNuE2z4M-N&url=Bilibili.com&host=&vcode= HTTP/1.1" 200 None
2019-Jun-09 18:27:27 connectionpool.py[line:205]/DEBUG/  Starting new HTTP connection (1): 127.0.0.1:1081
2019-Jun-09 18:27:27 connectionpool.py[line:393]/DEBUG/  http://127.0.0.1:1081 "GET http://www.alexa.cn/api/server/get?token=5bc249d7skazuJTcknnLlVmg1GftT4jU5GApvWMf7fS8xG69wOWAmfYecf6Qhnw-O&url=Bilibili.com&force_update=0 HTTP/1.1" 200 None
2019-Jun-09 18:27:27 connectionpool.py[line:205]/DEBUG/  Starting new HTTP connection (1): 127.0.0.1:1081
2019-Jun-09 18:27:27 connectionpool.py[line:393]/DEBUG/  http://127.0.0.1:1081 "GET http://www.alexa.cn/api/who_is/get?token=bb25420bREQbpOvMgDfrYJmts-A2Gy2ZRGWLnqrm4f18yBpKZLtJFPWPE8pZ9yQo-N&url=Bilibili.com&force_update=0 HTTP/1.1" 200 None
2019-Jun-09 18:27:27 connectionpool.py[line:205]/DEBUG/  Starting new HTTP connection (1): 127.0.0.1:1081
2019-Jun-09 18:27:27 connectionpool.py[line:393]/DEBUG/  http://127.0.0.1:1081 "GET http://www.alexa.cn/api/alexa/free?token=f8f74250lunMuRfkGP3WCPHeaG9biY2LpJlJx5Ocs5ChqtkS-DJbayVNJz-DsY-Gqk-N&url=Bilibili.com HTTP/1.1" 200 None
2019-Jun-09 18:27:27 scraper.py[line:158]/ERROR/  Spider error processing <GET http://www.alexa.cn/Bilibili.com> (referer: http://www.alexa.cn/siterank/)
Traceback (most recent call last):
  File "E:\Users\JohnParker\Anaconda3\lib\site-packages\scrapy\utils\defer.py", line 102, in iter_errback
    yield next(it)
  File "E:\Users\JohnParker\Anaconda3\lib\site-packages\scrapy\spidermiddlewares\offsite.py", line 29, in process_spider_output
    for x in result:
  File "E:\Users\JohnParker\Anaconda3\lib\site-packages\scrapy\spidermiddlewares\referer.py", line 339, in <genexpr>
    return (_set_referer(r) for r in result or ())
  File "E:\Users\JohnParker\Anaconda3\lib\site-packages\scrapy\spidermiddlewares\urllength.py", line 37, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "E:\Users\JohnParker\Anaconda3\lib\site-packages\scrapy\spidermiddlewares\depth.py", line 58, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "E:\urlScrapy\urlScrapy\spiders\url_dns.py", line 82, in parse_url
    icp_list = [icp['data']['web_name'], icp['data']['web_home'],
TypeError: list indices must be integers or slices, not str
2019-Jun-09 18:27:29 retry.py[line:75]/DEBUG/  Retrying <GET http://www.alexa.cn/Cnblogs.com> (failed 2 times): TCP connection timed out: 10060: 由于连接方在一段时间后没有正确答复或连接的主机没有反应，连接尝试失败。.
2019-Jun-09 18:27:29 middlewares.py[line:19]/DEBUG/  =====  ProxyMiddleware get a random_proxy:【 http://59.44.247.194:9797 】 =====
2019-Jun-09 18:27:38 engine.py[line:238]/DEBUG/  Crawled (200) <GET http://www.alexa.cn/Babytree.com> (referer: http://www.alexa.cn/siterank/)
2019-Jun-09 18:27:38 middlewares.py[line:19]/DEBUG/  =====  ProxyMiddleware get a random_proxy:【 http://59.44.247.194:9797 】 =====
2019-Jun-09 18:27:38 connectionpool.py[line:205]/DEBUG/  Starting new HTTP connection (1): 127.0.0.1:1081
2019-Jun-09 18:27:38 connectionpool.py[line:393]/DEBUG/  http://127.0.0.1:1081 "GET http://www.alexa.cn/api/icp/info?token=d892a211QXubVjO-AwD92y6F-ABOGY8gw3I772k1tjDfdwulXs68nFyElhBMCtL2E-M&url=Babytree.com&host=&vcode= HTTP/1.1" 200 None
2019-Jun-09 18:27:38 connectionpool.py[line:205]/DEBUG/  Starting new HTTP connection (1): 127.0.0.1:1081
2019-Jun-09 18:27:39 connectionpool.py[line:393]/DEBUG/  http://127.0.0.1:1081 "GET http://www.alexa.cn/api/server/get?token=42385bf1HgD5S7KFVIxYMOQRdTapFeBq1CL1udNETO2NtbVYAXT7zhmQqupila8-M&url=Babytree.com&force_update=0 HTTP/1.1" 200 None
2019-Jun-09 18:27:39 connectionpool.py[line:205]/DEBUG/  Starting new HTTP connection (1): 127.0.0.1:1081
2019-Jun-09 18:27:40 connectionpool.py[line:393]/DEBUG/  http://127.0.0.1:1081 "GET http://www.alexa.cn/api/who_is/get?token=476dff56mEkEErR44NJrH4f9RyD6eXz5eWK16vYRrcic5gN2sIK9eRFEjQqI6YI-O&url=Babytree.com&force_update=0 HTTP/1.1" 200 None
2019-Jun-09 18:27:40 connectionpool.py[line:205]/DEBUG/  Starting new HTTP connection (1): 127.0.0.1:1081
2019-Jun-09 18:27:40 connectionpool.py[line:393]/DEBUG/  http://127.0.0.1:1081 "GET http://www.alexa.cn/api/alexa/free?token=5b2e796a3lDuXpwd2SK60jUDwAeL-DEknZI51lyIdXUQ-DGJ-DQPJHioTZ5M17lBWA-O&url=Babytree.com HTTP/1.1" 200 None
2019-Jun-09 18:27:40 scraper.py[line:240]/DEBUG/  Scraped from <200 http://www.alexa.cn/Babytree.com>
{'com_name': '北京众鸣世纪科技有限公司',
 'content_type': 'Content-Type: text/html; charset=utf-8',
 'country_code': 'CN',
 'country_rank': '26',
 'create_day': '2004-09-06',
 'domain': 'babytree.com',
 'http_type': 'HTTP/1.1 200 OK',
 'icp_no': '京ICP备11010348号-1',
 'icp_type': '企业',
 'nserver': 'NS1.DNSV5.COM',
 'rank_trend_chart': 'http://traffic.alexa.com/graph?o=lt&y=q&b=ffffff&n=666666&f=999999&p=4e8cff&r=1y&t=2&z=0&c=1&h=150&w=340&u=qq.comBabytree.com',
 'reg_server': 'ENOM, INC.',
 'search_proportion_chart': 'http://traffic.alexa.com/graph?y=t&b=ffffff&n=666&f=999999&r=7d&t=2&z=30&c=1&h=280&w=920&u=Babytree.com',
 'server': 'WHOIS.ENOM.COM',
 'server_ip': '59.110.149.245',
 'server_location': '北京市',
 'server_type': 'nginx',
 'web_home': 'www.babytree.com',
 'web_name': '众鸣世纪',
 'world_rank': '83',
 'world_uv_rank': '91'}
2019-Jun-09 18:27:47 retry.py[line:91]/DEBUG/  Gave up retrying <GET http://www.alexa.cn/Gmw.cn> (failed 3 times): Connection was refused by other side: 10061: 由于目标计算机积极拒绝，无法连接。.
2019-Jun-09 18:27:47 proxyDBManager.py[line:181]/DEBUG/  ===  success to update 222.189.190.187 proxy  ===
2019-Jun-09 18:27:47 proxyDBManager.py[line:181]/DEBUG/  ===  success to update 222.189.190.187 proxy  ===
2019-Jun-09 18:27:47 middlewares.py[line:19]/DEBUG/  =====  ProxyMiddleware get a random_proxy:【 http://112.87.70.109:9999 】 =====
2019-Jun-09 18:27:47 scraper.py[line:208]/ERROR/  Error downloading <GET http://www.alexa.cn/Gmw.cn>
Traceback (most recent call last):
  File "E:\Users\JohnParker\Anaconda3\lib\site-packages\scrapy\core\downloader\middleware.py", line 43, in process_request
    defer.returnValue((yield download_func(request=request,spider=spider)))
twisted.internet.error.ConnectionRefusedError: Connection was refused by other side: 10061: 由于目标计算机积极拒绝，无法连接。.
2019-Jun-09 18:27:49 retry.py[line:91]/DEBUG/  Gave up retrying <GET http://www.alexa.cn/Taobao.com> (failed 3 times): TCP connection timed out: 10060: 由于连接方在一段时间后没有正确答复或连接的主机没有反应，连接尝试失败。.
2019-Jun-09 18:27:49 proxyDBManager.py[line:181]/DEBUG/  ===  success to update 163.204.245.252 proxy  ===
2019-Jun-09 18:27:49 proxyDBManager.py[line:181]/DEBUG/  ===  success to update 163.204.245.252 proxy  ===
2019-Jun-09 18:27:49 middlewares.py[line:19]/DEBUG/  =====  ProxyMiddleware get a random_proxy:【 http://117.90.3.74:9000 】 =====
2019-Jun-09 18:27:49 scraper.py[line:208]/ERROR/  Error downloading <GET http://www.alexa.cn/Taobao.com>
Traceback (most recent call last):
  File "E:\Users\JohnParker\Anaconda3\lib\site-packages\scrapy\core\downloader\middleware.py", line 43, in process_request
    defer.returnValue((yield download_func(request=request,spider=spider)))
twisted.internet.error.TCPTimedOutError: TCP connection timed out: 10060: 由于连接方在一段时间后没有正确答复或连接的主机没有反应，连接尝试失败。.
2019-Jun-09 18:27:55 retry.py[line:91]/DEBUG/  Gave up retrying <GET http://www.alexa.cn/Sohu.com> (failed 3 times): TCP connection timed out: 10060: 由于连接方在一段时间后没有正确答复或连接的主机没有反应，连接尝试失败。.
2019-Jun-09 18:27:55 proxyDBManager.py[line:181]/DEBUG/  ===  success to update 112.85.166.122 proxy  ===
2019-Jun-09 18:27:55 proxyDBManager.py[line:181]/DEBUG/  ===  success to update 112.85.166.122 proxy  ===
2019-Jun-09 18:27:55 middlewares.py[line:19]/DEBUG/  =====  ProxyMiddleware get a random_proxy:【 http://112.85.150.42:9999 】 =====
2019-Jun-09 18:27:55 scraper.py[line:208]/ERROR/  Error downloading <GET http://www.alexa.cn/Sohu.com>
Traceback (most recent call last):
  File "E:\Users\JohnParker\Anaconda3\lib\site-packages\scrapy\core\downloader\middleware.py", line 43, in process_request
    defer.returnValue((yield download_func(request=request,spider=spider)))
twisted.internet.error.TCPTimedOutError: TCP connection timed out: 10060: 由于连接方在一段时间后没有正确答复或连接的主机没有反应，连接尝试失败。.
2019-Jun-09 18:27:56 engine.py[line:238]/DEBUG/  Crawled (200) <GET http://www.alexa.cn/Soso.com> (referer: http://www.alexa.cn/siterank/)
2019-Jun-09 18:27:56 connectionpool.py[line:205]/DEBUG/  Starting new HTTP connection (1): 127.0.0.1:1081
2019-Jun-09 18:27:56 connectionpool.py[line:393]/DEBUG/  http://127.0.0.1:1081 "GET http://www.alexa.cn/api/icp/info?token=2728ffa2wJFM9NI1AcEe5ylDZ-Bve9qCyWybx5IVrJOp3gP-BT4BNcwWQpEiXKUrg-L&url=Soso.com&host=&vcode= HTTP/1.1" 200 None
2019-Jun-09 18:27:56 connectionpool.py[line:205]/DEBUG/  Starting new HTTP connection (1): 127.0.0.1:1081
2019-Jun-09 18:27:56 connectionpool.py[line:393]/DEBUG/  http://127.0.0.1:1081 "GET http://www.alexa.cn/api/server/get?token=036cab7bWqqzRe-FLUFiL7mdiVi9yyFoCnti730k2DWYZHcEtkcjhbSeUa4QkoR4-L&url=Soso.com&force_update=0 HTTP/1.1" 200 None
2019-Jun-09 18:27:56 connectionpool.py[line:205]/DEBUG/  Starting new HTTP connection (1): 127.0.0.1:1081
2019-Jun-09 18:27:56 connectionpool.py[line:393]/DEBUG/  http://127.0.0.1:1081 "GET http://www.alexa.cn/api/who_is/get?token=aaec6ff3n-C6hzqLa0ZAUr1FqBvhW3qynpf5-I1V3tH8f6Mld-IQqcp8m7mVUiogsE-K&url=Soso.com&force_update=0 HTTP/1.1" 200 None
2019-Jun-09 18:27:56 connectionpool.py[line:205]/DEBUG/  Starting new HTTP connection (1): 127.0.0.1:1081
2019-Jun-09 18:27:57 connectionpool.py[line:393]/DEBUG/  http://127.0.0.1:1081 "GET http://www.alexa.cn/api/alexa/free?token=2cab1ea4k3IqmU-GzsltY6LjUDumdptsdkb8NY-ARGLBFcZon0MjSjClsJGHH3RsQ-M&url=Soso.com HTTP/1.1" 200 None
2019-Jun-09 18:27:57 scraper.py[line:240]/DEBUG/  Scraped from <200 http://www.alexa.cn/Soso.com>
{'com_name': '北京搜狗信息服务有限公司',
 'content_type': 'Content-Type: text/html',
 'country_code': 'CN',
 'country_rank': '20',
 'create_day': '0000-00-00',
 'domain': 'soso.com',
 'http_type': 'HTTP/1.1 200 OK',
 'icp_no': '京ICP备11001839号-4',
 'icp_type': '企业',
 'nserver': 'ns1.sogou.com',
 'rank_trend_chart': 'http://traffic.alexa.com/graph?o=lt&y=q&b=ffffff&n=666666&f=999999&p=4e8cff&r=1y&t=2&z=0&c=1&h=150&w=340&u=qq.comSoso.com',
 'reg_server': '',
 'search_proportion_chart': 'http://traffic.alexa.com/graph?y=t&b=ffffff&n=666&f=999999&r=7d&t=2&z=30&c=1&h=280&w=920&u=Soso.com',
 'server': 'WHOIS.VERISIGN-GRS.COM',
 'server_ip': '183.36.114.44',
 'server_location': '广东省广州市',
 'server_type': 'nginx',
 'web_home': 'www.soso.com',
 'web_name': 'soso网',
 'world_rank': '68',
 'world_uv_rank': '67'}
2019-Jun-09 18:28:04 engine.py[line:238]/DEBUG/  Crawled (200) <GET http://www.alexa.cn/163.com> (referer: http://www.alexa.cn/siterank/)
2019-Jun-09 18:28:05 connectionpool.py[line:205]/DEBUG/  Starting new HTTP connection (1): 127.0.0.1:1081
2019-Jun-09 18:28:05 connectionpool.py[line:393]/DEBUG/  http://127.0.0.1:1081 "GET http://www.alexa.cn/api/icp/info?token=c6a41d89g4SsVwzW6SGGzqLaPkdSVZy-J6NjqrSWCvTJ7ReevFtGJ4DaffzsEv5Q-L&url=163.com&host=&vcode= HTTP/1.1" 200 None
2019-Jun-09 18:28:05 connectionpool.py[line:205]/DEBUG/  Starting new HTTP connection (1): 127.0.0.1:1081
2019-Jun-09 18:28:05 connectionpool.py[line:393]/DEBUG/  http://127.0.0.1:1081 "GET http://www.alexa.cn/api/server/get?token=fe076fdeJCgYQpMCpdyoD1cGlReBgESth8x6W7d3W5HAGb2h25ELtJmkKHqxnvE-O&url=163.com&force_update=0 HTTP/1.1" 200 None
2019-Jun-09 18:28:05 connectionpool.py[line:205]/DEBUG/  Starting new HTTP connection (1): 127.0.0.1:1081
2019-Jun-09 18:28:05 connectionpool.py[line:393]/DEBUG/  http://127.0.0.1:1081 "GET http://www.alexa.cn/api/who_is/get?token=5653c620At7Ad7QfOOjM7LfEufKTZ81Y9RYtomzpgbQuyXHu-FoTaPKMIpCYAEIE-N&url=163.com&force_update=0 HTTP/1.1" 200 None
2019-Jun-09 18:28:05 connectionpool.py[line:205]/DEBUG/  Starting new HTTP connection (1): 127.0.0.1:1081
2019-Jun-09 18:28:05 connectionpool.py[line:393]/DEBUG/  http://127.0.0.1:1081 "GET http://www.alexa.cn/api/alexa/free?token=4258da8f-G2qBXLgW9utn1MjOafYvXKE8qTWb4RAU7e6rP57xd6HdrnN5exjohXQ-N&url=163.com HTTP/1.1" 200 None
2019-Jun-09 18:28:05 scraper.py[line:240]/DEBUG/  Scraped from <200 http://www.alexa.cn/163.com>
{'com_name': '广州网易计算机系统有限公司',
 'content_type': '',
 'country_code': 'CN',
 'country_rank': '19',
 'create_day': '1997-09-15',
 'domain': '163.com',
 'http_type': 'HTTP/1.1 302 Moved Temporarily',
 'icp_no': '粤B2-20090191-18',
 'icp_type': '企业',
 'nserver': 'NS1.NEASE.NET',
 'rank_trend_chart': 'http://traffic.alexa.com/graph?o=lt&y=q&b=ffffff&n=666666&f=999999&p=4e8cff&r=1y&t=2&z=0&c=1&h=150&w=340&u=qq.com163.com',
 'reg_server': 'MARKMONITOR INC.',
 'search_proportion_chart': 'http://traffic.alexa.com/graph?y=t&b=ffffff&n=666&f=999999&r=7d&t=2&z=30&c=1&h=280&w=920&u=163.com',
 'server': 'WHOIS.MARKMONITOR.COM',
 'server_ip': '122.226.47.94',
 'server_location': '浙江省金华市',
 'server_type': 'Cdn Cache Server V2.0',
 'web_home': 'www.163.com',
 'web_name': '网易',
 'world_rank': '70',
 'world_uv_rank': '69'}
2019-Jun-09 18:28:09 retry.py[line:91]/DEBUG/  Gave up retrying <GET http://www.alexa.cn/Hao123.com> (failed 3 times): TCP connection timed out: 10060: 由于连接方在一段时间后没有正确答复或连接的主机没有反应，连接尝试失败。.
2019-Jun-09 18:28:09 proxyDBManager.py[line:181]/DEBUG/  ===  success to update 112.85.166.245 proxy  ===
2019-Jun-09 18:28:09 proxyDBManager.py[line:181]/DEBUG/  ===  success to update 112.85.166.245 proxy  ===
2019-Jun-09 18:28:09 scraper.py[line:208]/ERROR/  Error downloading <GET http://www.alexa.cn/Hao123.com>
Traceback (most recent call last):
  File "E:\Users\JohnParker\Anaconda3\lib\site-packages\scrapy\core\downloader\middleware.py", line 43, in process_request
    defer.returnValue((yield download_func(request=request,spider=spider)))
twisted.internet.error.TCPTimedOutError: TCP connection timed out: 10060: 由于连接方在一段时间后没有正确答复或连接的主机没有反应，连接尝试失败。.
2019-Jun-09 18:28:13 logstats.py[line:48]/INFO/  Crawled 11 pages (at 4 pages/min), scraped 9 items (at 3 items/min)
2019-Jun-09 18:28:14 retry.py[line:91]/DEBUG/  Gave up retrying <GET http://www.alexa.cn/siterank/2> (failed 3 times): Connection was refused by other side: 10061: 由于目标计算机积极拒绝，无法连接。.
2019-Jun-09 18:28:14 proxyDBManager.py[line:181]/DEBUG/  ===  success to update 122.193.246.11 proxy  ===
2019-Jun-09 18:28:14 proxyDBManager.py[line:181]/DEBUG/  ===  success to update 122.193.246.11 proxy  ===
2019-Jun-09 18:28:15 scraper.py[line:208]/ERROR/  Error downloading <GET http://www.alexa.cn/siterank/2>
Traceback (most recent call last):
  File "E:\Users\JohnParker\Anaconda3\lib\site-packages\scrapy\core\downloader\middleware.py", line 43, in process_request
    defer.returnValue((yield download_func(request=request,spider=spider)))
twisted.internet.error.ConnectionRefusedError: Connection was refused by other side: 10061: 由于目标计算机积极拒绝，无法连接。.
2019-Jun-09 18:28:29 engine.py[line:238]/DEBUG/  Crawled (200) <GET http://www.alexa.cn/Cnblogs.com> (referer: http://www.alexa.cn/siterank/)
2019-Jun-09 18:28:29 connectionpool.py[line:205]/DEBUG/  Starting new HTTP connection (1): 127.0.0.1:1081
2019-Jun-09 18:28:30 connectionpool.py[line:393]/DEBUG/  http://127.0.0.1:1081 "GET http://www.alexa.cn/api/icp/info?token=21e216adNEj3FXAbFdMPTd4DIfJyygl-CGn1MYAX-C695iANaP0dEfeoPABJjGIYI-L&url=Cnblogs.com&host=&vcode= HTTP/1.1" 200 None
2019-Jun-09 18:28:30 connectionpool.py[line:205]/DEBUG/  Starting new HTTP connection (1): 127.0.0.1:1081
2019-Jun-09 18:28:30 connectionpool.py[line:393]/DEBUG/  http://127.0.0.1:1081 "GET http://www.alexa.cn/api/server/get?token=8dc00ca4jFuoC3z-Iez9S6Mkbj-D1vA4R45vYvtOXBIzZXdTYFlBSgO0r-D5X9SlSQ-L&url=Cnblogs.com&force_update=0 HTTP/1.1" 200 None
2019-Jun-09 18:28:30 connectionpool.py[line:205]/DEBUG/  Starting new HTTP connection (1): 127.0.0.1:1081
2019-Jun-09 18:28:31 connectionpool.py[line:393]/DEBUG/  http://127.0.0.1:1081 "GET http://www.alexa.cn/api/who_is/get?token=ae6a9be4tIXEbUyAHeaSh50WGwKFbyUwtdnR9e8FoVYYHl3DAc3LOBsRcCyEBFY-L&url=Cnblogs.com&force_update=0 HTTP/1.1" 200 None
2019-Jun-09 18:28:31 connectionpool.py[line:205]/DEBUG/  Starting new HTTP connection (1): 127.0.0.1:1081
2019-Jun-09 18:28:31 connectionpool.py[line:393]/DEBUG/  http://127.0.0.1:1081 "GET http://www.alexa.cn/api/alexa/free?token=d6602796hS4tQPaiV-EANfNPeDruMOBPpMmZt2K4Qc5LZwpQ5oJvEb8ax335J7Kw-N&url=Cnblogs.com HTTP/1.1" 200 None
2019-Jun-09 18:28:31 scraper.py[line:240]/DEBUG/  Scraped from <200 http://www.alexa.cn/Cnblogs.com>
{'com_name': '上海语程信息科技有限公司',
 'content_type': 'Content-Type: text/html; charset=utf-8',
 'country_code': 'CN',
 'country_rank': '24',
 'create_day': '2003-11-11',
 'domain': 'cnblogs.com',
 'http_type': 'HTTP/1.1 200 OK',
 'icp_no': '沪ICP备09004260号-1',
 'icp_type': '企业',
 'nserver': 'NS3.DNSV4.COM',
 'rank_trend_chart': 'http://traffic.alexa.com/graph?o=lt&y=q&b=ffffff&n=666666&f=999999&p=4e8cff&r=1y&t=2&z=0&c=1&h=150&w=340&u=qq.comCnblogs.com',
 'reg_server': '35 TECHNOLOGY CO., LTD.',
 'search_proportion_chart': 'http://traffic.alexa.com/graph?y=t&b=ffffff&n=666&f=999999&r=7d&t=2&z=30&c=1&h=280&w=920&u=Cnblogs.com',
 'server': 'WHOIS.35.COM',
 'server_ip': '47.96.240.190',
 'server_location': '浙江省杭州市',
 'server_type': '',
 'web_home': 'www.cnweblog.com',
 'web_name': '博客园',
 'world_rank': '78',
 'world_uv_rank': '75'}
2019-Jun-09 18:28:32 engine.py[line:238]/DEBUG/  Crawled (200) <GET http://www.alexa.cn/360.cn> (referer: http://www.alexa.cn/siterank/)
2019-Jun-09 18:28:33 connectionpool.py[line:205]/DEBUG/  Starting new HTTP connection (1): 127.0.0.1:1081
2019-Jun-09 18:28:33 connectionpool.py[line:393]/DEBUG/  http://127.0.0.1:1081 "GET http://www.alexa.cn/api/icp/info?token=0737e26c8VHBEm5YFZ5kGhH6GH0t81f6j1xLwDGtQHWxTig-C-CuxwHiqosBdU-C6g-N&url=360.cn&host=&vcode= HTTP/1.1" 200 None
2019-Jun-09 18:28:33 connectionpool.py[line:205]/DEBUG/  Starting new HTTP connection (1): 127.0.0.1:1081
2019-Jun-09 18:28:33 connectionpool.py[line:393]/DEBUG/  http://127.0.0.1:1081 "GET http://www.alexa.cn/api/server/get?token=119c1393yRcvbQ24A8icNYDX5exakR6j4wRwDh4V9mGqD6jZiy7hkYsr0tDtYxk-K&url=360.cn&force_update=0 HTTP/1.1" 200 None
2019-Jun-09 18:28:33 connectionpool.py[line:205]/DEBUG/  Starting new HTTP connection (1): 127.0.0.1:1081
2019-Jun-09 18:28:33 connectionpool.py[line:393]/DEBUG/  http://127.0.0.1:1081 "GET http://www.alexa.cn/api/who_is/get?token=171ca79ad3gAreSKNsiTXdXtPsLMDbnlUUjfaQxN5d4USPNOdBlVNZYxMMOTMh4-O&url=360.cn&force_update=0 HTTP/1.1" 200 None
2019-Jun-09 18:28:33 connectionpool.py[line:205]/DEBUG/  Starting new HTTP connection (1): 127.0.0.1:1081
2019-Jun-09 18:28:33 connectionpool.py[line:393]/DEBUG/  http://127.0.0.1:1081 "GET http://www.alexa.cn/api/alexa/free?token=eb8e7b68CbDK6gbUA8AhGEpxpLrxyB4MkK-A2VQc33ECNFIfjyxd8vpazkg2LS9o-L&url=360.cn HTTP/1.1" 200 None
2019-Jun-09 18:28:33 scraper.py[line:240]/DEBUG/  Scraped from <200 http://www.alexa.cn/360.cn>
{'com_name': '北京奇虎科技有限公司',
 'content_type': 'Content-Type: text/html',
 'country_code': 'CN',
 'country_rank': '11',
 'create_day': '2003-03-17',
 'domain': '360.cn',
 'http_type': 'HTTP/1.1 301 Moved Permanently',
 'icp_no': '京ICP备08010314号-6',
 'icp_type': '企业',
 'nserver': 'dns9.360safe.com',
 'rank_trend_chart': 'http://traffic.alexa.com/graph?o=lt&y=q&b=ffffff&n=666666&f=999999&p=4e8cff&r=1y&t=2&z=0&c=1&h=150&w=340&u=qq.com360.cn',
 'reg_server': '厦门易名科技股份有限公司',
 'search_proportion_chart': 'http://traffic.alexa.com/graph?y=t&b=ffffff&n=666&f=999999&r=7d&t=2&z=30&c=1&h=280&w=920&u=360.cn',
 'server': 'WHOIS.CNNIC.CN',
 'server_ip': '36.110.213.49',
 'server_location': '北京市',
 'server_type': 'nginx',
 'web_home': 'www.360.cn<br/>www.360safe.com',
 'web_name': '360安全中心',
 'world_rank': '22',
 'world_uv_rank': '23'}
2019-Jun-09 18:28:34 retry.py[line:91]/DEBUG/  Gave up retrying <GET http://www.alexa.cn/Jd.com> (failed 3 times): TCP connection timed out: 10060: 由于连接方在一段时间后没有正确答复或连接的主机没有反应，连接尝试失败。.
2019-Jun-09 18:28:34 proxyDBManager.py[line:181]/DEBUG/  ===  success to update 122.193.244.243 proxy  ===
2019-Jun-09 18:28:34 proxyDBManager.py[line:181]/DEBUG/  ===  success to update 122.193.244.243 proxy  ===
2019-Jun-09 18:28:34 scraper.py[line:208]/ERROR/  Error downloading <GET http://www.alexa.cn/Jd.com>
Traceback (most recent call last):
  File "E:\Users\JohnParker\Anaconda3\lib\site-packages\scrapy\core\downloader\middleware.py", line 43, in process_request
    defer.returnValue((yield download_func(request=request,spider=spider)))
twisted.internet.error.TCPTimedOutError: TCP connection timed out: 10060: 由于连接方在一段时间后没有正确答复或连接的主机没有反应，连接尝试失败。.
2019-Jun-09 18:28:37 engine.py[line:238]/DEBUG/  Crawled (200) <GET http://www.alexa.cn/Sina.com.cn> (referer: http://www.alexa.cn/siterank/)
2019-Jun-09 18:28:37 connectionpool.py[line:205]/DEBUG/  Starting new HTTP connection (1): 127.0.0.1:1081
2019-Jun-09 18:28:37 connectionpool.py[line:393]/DEBUG/  http://127.0.0.1:1081 "GET http://www.alexa.cn/api/icp/info?token=91c2fd3aEp-Gmy530RZccCihBgdz9fZyoWaimy1oIgt4EYa7Nlvy1fYQxI1y59Lc-M&url=Sina.com.cn&host=&vcode= HTTP/1.1" 200 None
2019-Jun-09 18:28:37 connectionpool.py[line:205]/DEBUG/  Starting new HTTP connection (1): 127.0.0.1:1081
2019-Jun-09 18:28:38 connectionpool.py[line:393]/DEBUG/  http://127.0.0.1:1081 "GET http://www.alexa.cn/api/server/get?token=c59adb19nIQKOOnCLFw5FKZ5dEOVFAmDoz0ETe9-JgH-J6Wxwg0VJtQ63A-JHKdkF0-M&url=Sina.com.cn&force_update=0 HTTP/1.1" 200 None
2019-Jun-09 18:28:38 connectionpool.py[line:205]/DEBUG/  Starting new HTTP connection (1): 127.0.0.1:1081
2019-Jun-09 18:28:38 connectionpool.py[line:393]/DEBUG/  http://127.0.0.1:1081 "GET http://www.alexa.cn/api/who_is/get?token=44a8246eHjP79xGCj5B2nqjjHk4M71dMyPkQfoEEsrWMY6MNmcDLHeZ4KB-Bdwug-N&url=Sina.com.cn&force_update=0 HTTP/1.1" 200 None
2019-Jun-09 18:28:38 connectionpool.py[line:205]/DEBUG/  Starting new HTTP connection (1): 127.0.0.1:1081
2019-Jun-09 18:28:38 connectionpool.py[line:393]/DEBUG/  http://127.0.0.1:1081 "GET http://www.alexa.cn/api/alexa/free?token=9c5a55b2zcYjfHvl-Esj6OL0fyWuy44GlNBT2ayCW5OxJad6ue-HcESjlLSiQIFuw-O&url=Sina.com.cn HTTP/1.1" 200 None
2019-Jun-09 18:28:38 scraper.py[line:240]/DEBUG/  Scraped from <200 http://www.alexa.cn/Sina.com.cn>
{'com_name': '北京新浪互联信息服务有限公司',
 'content_type': 'Content-Type: text/html',
 'country_code': 'CN',
 'country_rank': '7',
 'create_day': '1998-11-20',
 'domain': 'sina.com.cn',
 'http_type': 'HTTP/1.1 302 Moved Temporarily',
 'icp_no': '京ICP证000007-6',
 'icp_type': '企业',
 'nserver': 'ns3.sina.com.cn',
 'rank_trend_chart': 'http://traffic.alexa.com/graph?o=lt&y=q&b=ffffff&n=666666&f=999999&p=4e8cff&r=1y&t=2&z=0&c=1&h=150&w=340&u=qq.comSina.com.cn',
 'reg_server': '北京新网数码信息技术有限公司',
 'search_proportion_chart': 'http://traffic.alexa.com/graph?y=t&b=ffffff&n=666&f=999999&r=7d&t=2&z=30&c=1&h=280&w=920&u=Sina.com.cn',
 'server': 'WHOIS.CNNIC.CN',
 'server_ip': '115.238.190.239',
 'server_location': '浙江省宁波市',
 'server_type': 'nginx',
 'web_home': 'www.sina.com.cn',
 'web_name': '新浪网',
 'world_rank': '16',
 'world_uv_rank': '16'}
2019-Jun-09 18:28:59 retry.py[line:91]/DEBUG/  Gave up retrying <GET http://www.alexa.cn/Weibo.com> (failed 3 times): TCP connection timed out: 10060: 由于连接方在一段时间后没有正确答复或连接的主机没有反应，连接尝试失败。.
2019-Jun-09 18:28:59 proxyDBManager.py[line:181]/DEBUG/  ===  success to update 117.90.3.74 proxy  ===
2019-Jun-09 18:28:59 proxyDBManager.py[line:181]/DEBUG/  ===  success to update 117.90.3.74 proxy  ===
2019-Jun-09 18:28:59 scraper.py[line:208]/ERROR/  Error downloading <GET http://www.alexa.cn/Weibo.com>
Traceback (most recent call last):
  File "E:\Users\JohnParker\Anaconda3\lib\site-packages\scrapy\core\downloader\middleware.py", line 43, in process_request
    defer.returnValue((yield download_func(request=request,spider=spider)))
twisted.internet.error.TCPTimedOutError: TCP connection timed out: 10060: 由于连接方在一段时间后没有正确答复或连接的主机没有反应，连接尝试失败。.
2019-Jun-09 18:29:05 retry.py[line:91]/DEBUG/  Gave up retrying <GET http://www.alexa.cn/Csdn.net> (failed 3 times): TCP connection timed out: 10060: 由于连接方在一段时间后没有正确答复或连接的主机没有反应，连接尝试失败。.
2019-Jun-09 18:29:05 proxyDBManager.py[line:181]/DEBUG/  ===  success to update 112.85.150.42 proxy  ===
2019-Jun-09 18:29:06 proxyDBManager.py[line:181]/DEBUG/  ===  success to update 112.85.150.42 proxy  ===
2019-Jun-09 18:29:06 scraper.py[line:208]/ERROR/  Error downloading <GET http://www.alexa.cn/Csdn.net>
Traceback (most recent call last):
  File "E:\Users\JohnParker\Anaconda3\lib\site-packages\scrapy\core\downloader\middleware.py", line 43, in process_request
    defer.returnValue((yield download_func(request=request,spider=spider)))
twisted.internet.error.TCPTimedOutError: TCP connection timed out: 10060: 由于连接方在一段时间后没有正确答复或连接的主机没有反应，连接尝试失败。.
2019-Jun-09 18:29:06 engine.py[line:295]/INFO/  Closing spider (finished)
2019-Jun-09 18:29:06 statscollectors.py[line:47]/INFO/  Dumping Scrapy stats:
{'downloader/exception_count': 41,
 'downloader/exception_type_count/twisted.internet.error.ConnectionRefusedError': 8,
 'downloader/exception_type_count/twisted.internet.error.TCPTimedOutError': 31,
 'downloader/exception_type_count/twisted.web._newclient.ResponseNeverReceived': 2,
 'downloader/request_bytes': 23857,
 'downloader/request_count': 57,
 'downloader/request_method_count/GET': 57,
 'downloader/response_bytes': 72913,
 'downloader/response_count': 16,
 'downloader/response_status_count/200': 14,
 'downloader/response_status_count/503': 2,
 'finish_reason': 'finished',
 'finish_time': datetime.datetime(2019, 6, 9, 10, 29, 6, 203225),
 'item_scraped_count': 12,
 'log_count/DEBUG': 250,
 'log_count/ERROR': 10,
 'log_count/INFO': 17,
 'request_depth_max': 1,
 'response_received_count': 14,
 'retry/count': 34,
 'retry/max_reached': 9,
 'retry/reason_count/503 Service Unavailable': 2,
 'retry/reason_count/twisted.internet.error.ConnectionRefusedError': 6,
 'retry/reason_count/twisted.internet.error.TCPTimedOutError': 24,
 'retry/reason_count/twisted.web._newclient.ResponseNeverReceived': 2,
 "robotstxt/exception_count/<class 'twisted.internet.error.TCPTimedOutError'>": 1,
 'robotstxt/request_count': 1,
 'scheduler/dequeued': 54,
 'scheduler/dequeued/memory': 54,
 'scheduler/enqueued': 54,
 'scheduler/enqueued/memory': 54,
 'spider_exceptions/TypeError': 1,
 'start_time': datetime.datetime(2019, 6, 9, 10, 22, 13, 126663)}
2019-Jun-09 18:29:06 engine.py[line:326]/INFO/  Spider closed (finished)
