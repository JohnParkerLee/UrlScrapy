2019-Jun-09 17:34:39 log.py[line:146]/INFO/  Scrapy 1.6.0 started (bot: urlScrapy)
2019-Jun-09 17:34:39 log.py[line:149]/INFO/  Versions: lxml 4.3.3.0, libxml2 2.9.8, cssselect 1.0.3, parsel 1.5.1, w3lib 1.20.0, Twisted 19.2.0, Python 3.7.3 | packaged by conda-forge | (default, Mar 27 2019, 23:18:50) [MSC v.1900 64 bit (AMD64)], pyOpenSSL 19.0.0 (OpenSSL 1.1.1c  28 May 2019), cryptography 2.6.1, Platform Windows-10-10.0.17134-SP0
2019-Jun-09 17:34:39 crawler.py[line:38]/INFO/  Overridden settings: {'BOT_NAME': 'urlScrapy', 'CONCURRENT_REQUESTS': 10, 'CONCURRENT_REQUESTS_PER_DOMAIN': 16, 'CONCURRENT_REQUESTS_PER_IP': 16, 'DOWNLOAD_DELAY': 5, 'NEWSPIDER_MODULE': 'urlScrapy.spiders', 'ROBOTSTXT_OBEY': True, 'SPIDER_MODULES': ['urlScrapy.spiders']}
2019-Jun-09 17:34:39 telnet.py[line:60]/INFO/  Telnet Password: 5571244dc2bd28e5
2019-Jun-09 17:34:39 middleware.py[line:48]/INFO/  Enabled extensions:
['scrapy.extensions.corestats.CoreStats',
 'scrapy.extensions.telnet.TelnetConsole',
 'scrapy.extensions.logstats.LogStats']
2019-Jun-09 17:34:40 middleware.py[line:48]/INFO/  Enabled downloader middlewares:
['proxyPool.scrapy.middlewares.RetryMiddleware',
 'scrapy.downloadermiddlewares.robotstxt.RobotsTxtMiddleware',
 'proxyPool.scrapy.middlewares.ProxyMiddleware',
 'proxyPool.scrapy.middlewares.CatchExceptionMiddleware',
 'scrapy.downloadermiddlewares.httpauth.HttpAuthMiddleware',
 'scrapy.downloadermiddlewares.downloadtimeout.DownloadTimeoutMiddleware',
 'scrapy.downloadermiddlewares.defaultheaders.DefaultHeadersMiddleware',
 'proxyPool.scrapy.RandomUserAgentMiddleware.RandomUserAgentMiddleware',
 'scrapy.downloadermiddlewares.useragent.UserAgentMiddleware',
 'scrapy.downloadermiddlewares.retry.RetryMiddleware',
 'scrapy.downloadermiddlewares.redirect.MetaRefreshMiddleware',
 'scrapy.downloadermiddlewares.httpcompression.HttpCompressionMiddleware',
 'scrapy.downloadermiddlewares.redirect.RedirectMiddleware',
 'scrapy.downloadermiddlewares.cookies.CookiesMiddleware',
 'scrapy.downloadermiddlewares.httpproxy.HttpProxyMiddleware',
 'scrapy.downloadermiddlewares.stats.DownloaderStats']
2019-Jun-09 17:34:40 middleware.py[line:48]/INFO/  Enabled spider middlewares:
['scrapy.spidermiddlewares.httperror.HttpErrorMiddleware',
 'scrapy.spidermiddlewares.offsite.OffsiteMiddleware',
 'scrapy.spidermiddlewares.referer.RefererMiddleware',
 'scrapy.spidermiddlewares.urllength.UrlLengthMiddleware',
 'scrapy.spidermiddlewares.depth.DepthMiddleware']
2019-Jun-09 17:34:41 middleware.py[line:48]/INFO/  Enabled item pipelines:
['urlScrapy.pipelines.UrlscrapyPipeline']
2019-Jun-09 17:34:41 engine.py[line:256]/INFO/  Spider opened
2019-Jun-09 17:34:41 logstats.py[line:48]/INFO/  Crawled 0 pages (at 0 pages/min), scraped 0 items (at 0 items/min)
2019-Jun-09 17:34:41 telnet.py[line:74]/INFO/  Telnet console listening on 127.0.0.1:6023
2019-Jun-09 17:34:41 middlewares.py[line:19]/DEBUG/  =====  ProxyMiddleware get a random_proxy:【 http://112.85.149.139:9999 】 =====
2019-Jun-09 17:34:41 redirect.py[line:41]/DEBUG/  Redirecting (302) to <GET http://www.alexa.cn/plugin/tips?k=t8txjvCyaXi2ec91NRTZty4t1SyNpYcSw9nPS-JHXkCvDbBJY-JN-JiTzLSP8zdobSb1Rm-JuQDag9wRDq4CKRCBQ6EvrBKiHIbudpUei-BXCFdTnX-JeDiPDsSMgxk4pZnFx1TDkJxyNNJgICL8DMnHuXtgrTkeVFN5opNWnHzcbmPDCOsdDR6T0hV3Eajx1hwleK4M05DmuJkZ6mVqWQMeUpAA-O-O> from <GET http://www.alexa.cn/robots.txt>
2019-Jun-09 17:34:41 middlewares.py[line:19]/DEBUG/  =====  ProxyMiddleware get a random_proxy:【 http://112.85.171.181:9999 】 =====
2019-Jun-09 17:35:06 retry.py[line:75]/DEBUG/  Retrying <GET http://www.alexa.cn/plugin/tips?k=t8txjvCyaXi2ec91NRTZty4t1SyNpYcSw9nPS-JHXkCvDbBJY-JN-JiTzLSP8zdobSb1Rm-JuQDag9wRDq4CKRCBQ6EvrBKiHIbudpUei-BXCFdTnX-JeDiPDsSMgxk4pZnFx1TDkJxyNNJgICL8DMnHuXtgrTkeVFN5opNWnHzcbmPDCOsdDR6T0hV3Eajx1hwleK4M05DmuJkZ6mVqWQMeUpAA-O-O> (failed 1 times): TCP connection timed out: 10060: 由于连接方在一段时间后没有正确答复或连接的主机没有反应，连接尝试失败。.
2019-Jun-09 17:35:06 middlewares.py[line:19]/DEBUG/  =====  ProxyMiddleware get a random_proxy:【 http://112.85.149.139:9999 】 =====
2019-Jun-09 17:35:06 engine.py[line:238]/DEBUG/  Crawled (200) <GET http://www.alexa.cn/plugin/tips?k=t8txjvCyaXi2ec91NRTZty4t1SyNpYcSw9nPS-JHXkCvDbBJY-JN-JiTzLSP8zdobSb1Rm-JuQDag9wRDq4CKRCBQ6EvrBKiHIbudpUei-BXCFdTnX-JeDiPDsSMgxk4pZnFx1TDkJxyNNJgICL8DMnHuXtgrTkeVFN5opNWnHzcbmPDCOsdDR6T0hV3Eajx1hwleK4M05DmuJkZ6mVqWQMeUpAA-O-O> (referer: http://www.alexa.cn/robots.txt)
2019-Jun-09 17:35:06 middlewares.py[line:19]/DEBUG/  =====  ProxyMiddleware get a random_proxy:【 http://115.28.148.192:8118 】 =====
2019-Jun-09 17:35:11 retry.py[line:75]/DEBUG/  Retrying <GET http://www.alexa.cn/siterank/> (failed 1 times): 503 Service Unavailable
2019-Jun-09 17:35:11 middlewares.py[line:19]/DEBUG/  =====  ProxyMiddleware get a random_proxy:【 http://121.233.206.99:9999 】 =====
2019-Jun-09 17:35:18 retry.py[line:75]/DEBUG/  Retrying <GET http://www.alexa.cn/siterank/> (failed 2 times): Connection was refused by other side: 10061: 由于目标计算机积极拒绝，无法连接。.
2019-Jun-09 17:35:18 middlewares.py[line:19]/DEBUG/  =====  ProxyMiddleware get a random_proxy:【 http://121.233.251.235:9999 】 =====
2019-Jun-09 17:35:25 retry.py[line:91]/DEBUG/  Gave up retrying <GET http://www.alexa.cn/siterank/> (failed 3 times): Connection was refused by other side: 10061: 由于目标计算机积极拒绝，无法连接。.
2019-Jun-09 17:35:25 proxyDBManager.py[line:181]/DEBUG/  ===  success to update 121.233.251.235 proxy  ===
2019-Jun-09 17:35:25 proxyDBManager.py[line:181]/DEBUG/  ===  success to update 121.233.251.235 proxy  ===
2019-Jun-09 17:35:25 scraper.py[line:208]/ERROR/  Error downloading <GET http://www.alexa.cn/siterank/>
Traceback (most recent call last):
  File "E:\Users\JohnParker\Anaconda3\lib\site-packages\scrapy\core\downloader\middleware.py", line 43, in process_request
    defer.returnValue((yield download_func(request=request,spider=spider)))
twisted.internet.error.ConnectionRefusedError: Connection was refused by other side: 10061: 由于目标计算机积极拒绝，无法连接。.
2019-Jun-09 17:35:26 engine.py[line:295]/INFO/  Closing spider (finished)
2019-Jun-09 17:35:26 statscollectors.py[line:47]/INFO/  Dumping Scrapy stats:
{'downloader/exception_count': 3,
 'downloader/exception_type_count/twisted.internet.error.ConnectionRefusedError': 2,
 'downloader/exception_type_count/twisted.internet.error.TCPTimedOutError': 1,
 'downloader/request_bytes': 2433,
 'downloader/request_count': 6,
 'downloader/request_method_count/GET': 6,
 'downloader/response_bytes': 2476,
 'downloader/response_count': 3,
 'downloader/response_status_count/200': 1,
 'downloader/response_status_count/302': 1,
 'downloader/response_status_count/503': 1,
 'finish_reason': 'finished',
 'finish_time': datetime.datetime(2019, 6, 9, 9, 35, 26, 13751),
 'log_count/DEBUG': 14,
 'log_count/ERROR': 1,
 'log_count/INFO': 9,
 'response_received_count': 1,
 'retry/count': 3,
 'retry/max_reached': 1,
 'retry/reason_count/503 Service Unavailable': 1,
 'retry/reason_count/twisted.internet.error.ConnectionRefusedError': 1,
 'retry/reason_count/twisted.internet.error.TCPTimedOutError': 1,
 'robotstxt/request_count': 1,
 'robotstxt/response_count': 1,
 'robotstxt/response_status_count/200': 1,
 'scheduler/dequeued': 3,
 'scheduler/dequeued/memory': 3,
 'scheduler/enqueued': 3,
 'scheduler/enqueued/memory': 3,
 'start_time': datetime.datetime(2019, 6, 9, 9, 34, 41, 77972)}
2019-Jun-09 17:35:26 engine.py[line:326]/INFO/  Spider closed (finished)
