2019-Jun-09 16:54:00 log.py[line:146]/INFO/  Scrapy 1.6.0 started (bot: urlScrapy)
2019-Jun-09 16:54:00 log.py[line:149]/INFO/  Versions: lxml 4.3.3.0, libxml2 2.9.8, cssselect 1.0.3, parsel 1.5.1, w3lib 1.20.0, Twisted 19.2.0, Python 3.7.3 | packaged by conda-forge | (default, Mar 27 2019, 23:18:50) [MSC v.1900 64 bit (AMD64)], pyOpenSSL 19.0.0 (OpenSSL 1.1.1c  28 May 2019), cryptography 2.6.1, Platform Windows-10-10.0.17134-SP0
2019-Jun-09 16:54:00 crawler.py[line:38]/INFO/  Overridden settings: {'BOT_NAME': 'urlScrapy', 'CONCURRENT_REQUESTS': 10, 'CONCURRENT_REQUESTS_PER_DOMAIN': 16, 'CONCURRENT_REQUESTS_PER_IP': 16, 'DOWNLOAD_DELAY': 3, 'NEWSPIDER_MODULE': 'urlScrapy.spiders', 'ROBOTSTXT_OBEY': True, 'SPIDER_MODULES': ['urlScrapy.spiders']}
2019-Jun-09 16:54:00 telnet.py[line:60]/INFO/  Telnet Password: c4941b7f750680eb
2019-Jun-09 16:54:00 middleware.py[line:48]/INFO/  Enabled extensions:
['scrapy.extensions.corestats.CoreStats',
 'scrapy.extensions.telnet.TelnetConsole',
 'scrapy.extensions.logstats.LogStats']
2019-Jun-09 16:54:01 middleware.py[line:48]/INFO/  Enabled downloader middlewares:
['proxyPool.scrapy.middlewares.RetryMiddleware',
 'scrapy.downloadermiddlewares.robotstxt.RobotsTxtMiddleware',
 'proxyPool.scrapy.middlewares.ProxyMiddleware',
 'proxyPool.scrapy.middlewares.CatchExceptionMiddleware',
 'scrapy.downloadermiddlewares.httpauth.HttpAuthMiddleware',
 'scrapy.downloadermiddlewares.downloadtimeout.DownloadTimeoutMiddleware',
 'scrapy.downloadermiddlewares.defaultheaders.DefaultHeadersMiddleware',
 'proxyPool.scrapy.RandomUserAgentMiddleware.RandomUserAgentMiddleware',
 'scrapy.downloadermiddlewares.useragent.UserAgentMiddleware',
 'scrapy.downloadermiddlewares.retry.RetryMiddleware',
 'scrapy.downloadermiddlewares.redirect.MetaRefreshMiddleware',
 'scrapy.downloadermiddlewares.httpcompression.HttpCompressionMiddleware',
 'scrapy.downloadermiddlewares.redirect.RedirectMiddleware',
 'scrapy.downloadermiddlewares.cookies.CookiesMiddleware',
 'scrapy.downloadermiddlewares.httpproxy.HttpProxyMiddleware',
 'scrapy.downloadermiddlewares.stats.DownloaderStats']
2019-Jun-09 16:54:01 middleware.py[line:48]/INFO/  Enabled spider middlewares:
['scrapy.spidermiddlewares.httperror.HttpErrorMiddleware',
 'scrapy.spidermiddlewares.offsite.OffsiteMiddleware',
 'scrapy.spidermiddlewares.referer.RefererMiddleware',
 'scrapy.spidermiddlewares.urllength.UrlLengthMiddleware',
 'scrapy.spidermiddlewares.depth.DepthMiddleware']
2019-Jun-09 16:54:01 middleware.py[line:48]/INFO/  Enabled item pipelines:
['urlScrapy.pipelines.UrlscrapyPipeline']
2019-Jun-09 16:54:01 engine.py[line:256]/INFO/  Spider opened
2019-Jun-09 16:54:01 logstats.py[line:48]/INFO/  Crawled 0 pages (at 0 pages/min), scraped 0 items (at 0 items/min)
2019-Jun-09 16:54:01 telnet.py[line:74]/INFO/  Telnet console listening on 127.0.0.1:6023
2019-Jun-09 16:54:01 middlewares.py[line:19]/DEBUG/  =====  ProxyMiddleware get a random_proxy:【 http://113.110.45.45:9999 】 =====
2019-Jun-09 16:54:22 retry.py[line:75]/DEBUG/  Retrying <GET http://www.alexa.cn/robots.txt> (failed 1 times): TCP connection timed out: 10060: 由于连接方在一段时间后没有正确答复或连接的主机没有反应，连接尝试失败。.
2019-Jun-09 16:54:22 middlewares.py[line:19]/DEBUG/  =====  ProxyMiddleware get a random_proxy:【 http://115.29.3.37:80 】 =====
2019-Jun-09 16:54:43 retry.py[line:75]/DEBUG/  Retrying <GET http://www.alexa.cn/robots.txt> (failed 2 times): TCP connection timed out: 10060: 由于连接方在一段时间后没有正确答复或连接的主机没有反应，连接尝试失败。.
2019-Jun-09 16:54:44 middlewares.py[line:19]/DEBUG/  =====  ProxyMiddleware get a random_proxy:【 http://115.29.3.37:80 】 =====
2019-Jun-09 16:55:01 logstats.py[line:48]/INFO/  Crawled 0 pages (at 0 pages/min), scraped 0 items (at 0 items/min)
2019-Jun-09 16:55:05 retry.py[line:91]/DEBUG/  Gave up retrying <GET http://www.alexa.cn/robots.txt> (failed 3 times): TCP connection timed out: 10060: 由于连接方在一段时间后没有正确答复或连接的主机没有反应，连接尝试失败。.
2019-Jun-09 16:55:05 proxyDBManager.py[line:181]/DEBUG/  ===  success to update 115.29.3.37 proxy  ===
2019-Jun-09 16:55:05 proxyDBManager.py[line:181]/DEBUG/  ===  success to update 115.29.3.37 proxy  ===
2019-Jun-09 16:55:05 robotstxt.py[line:85]/ERROR/  Error downloading <GET http://www.alexa.cn/robots.txt>: TCP connection timed out: 10060: 由于连接方在一段时间后没有正确答复或连接的主机没有反应，连接尝试失败。.
Traceback (most recent call last):
  File "E:\Users\JohnParker\Anaconda3\lib\site-packages\scrapy\core\downloader\middleware.py", line 43, in process_request
    defer.returnValue((yield download_func(request=request,spider=spider)))
twisted.internet.error.TCPTimedOutError: TCP connection timed out: 10060: 由于连接方在一段时间后没有正确答复或连接的主机没有反应，连接尝试失败。.
2019-Jun-09 16:55:05 middlewares.py[line:19]/DEBUG/  =====  ProxyMiddleware get a random_proxy:【 http://27.188.64.70:8060 】 =====
2019-Jun-09 16:55:05 engine.py[line:238]/DEBUG/  Crawled (200) <GET http://www.alexa.cn/siterank/> (referer: http://www.alexa.cn/siterank/)
2019-Jun-09 16:55:05 middlewares.py[line:19]/DEBUG/  =====  ProxyMiddleware get a random_proxy:【 http://101.200.50.18:8118 】 =====
2019-Jun-09 16:55:05 middlewares.py[line:19]/DEBUG/  =====  ProxyMiddleware get a random_proxy:【 http://27.188.64.70:8060 】 =====
2019-Jun-09 16:55:05 middlewares.py[line:19]/DEBUG/  =====  ProxyMiddleware get a random_proxy:【 http://36.250.156.152:9999 】 =====
2019-Jun-09 16:55:05 middlewares.py[line:19]/DEBUG/  =====  ProxyMiddleware get a random_proxy:【 http://113.124.86.249:9999 】 =====
2019-Jun-09 16:55:05 middlewares.py[line:19]/DEBUG/  =====  ProxyMiddleware get a random_proxy:【 http://114.230.69.191:9999 】 =====
2019-Jun-09 16:55:05 middlewares.py[line:19]/DEBUG/  =====  ProxyMiddleware get a random_proxy:【 http://27.188.64.70:8060 】 =====
2019-Jun-09 16:55:05 middlewares.py[line:19]/DEBUG/  =====  ProxyMiddleware get a random_proxy:【 http://115.29.3.37:80 】 =====
2019-Jun-09 16:55:05 middlewares.py[line:19]/DEBUG/  =====  ProxyMiddleware get a random_proxy:【 http://1.197.204.6:9999 】 =====
2019-Jun-09 16:55:05 middlewares.py[line:19]/DEBUG/  =====  ProxyMiddleware get a random_proxy:【 http://1.197.16.95:9999 】 =====
2019-Jun-09 16:55:05 middlewares.py[line:19]/DEBUG/  =====  ProxyMiddleware get a random_proxy:【 http://180.118.86.237:9999 】 =====
2019-Jun-09 16:55:05 scraper.py[line:158]/ERROR/  Spider error processing <GET http://www.alexa.cn/siterank/> (referer: http://www.alexa.cn/siterank/)
Traceback (most recent call last):
  File "E:\Users\JohnParker\Anaconda3\lib\site-packages\requests\models.py", line 375, in prepare_url
    scheme, auth, host, port, path, query, fragment = parse_url(url)
  File "E:\Users\JohnParker\Anaconda3\lib\site-packages\urllib3\util\url.py", line 199, in parse_url
    raise LocationParseError(url)
urllib3.exceptions.LocationParseError: Failed to parse: http: 

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "E:\Users\JohnParker\Anaconda3\lib\site-packages\scrapy\utils\defer.py", line 102, in iter_errback
    yield next(it)
  File "E:\Users\JohnParker\Anaconda3\lib\site-packages\scrapy\spidermiddlewares\offsite.py", line 29, in process_spider_output
    for x in result:
  File "E:\Users\JohnParker\Anaconda3\lib\site-packages\scrapy\spidermiddlewares\referer.py", line 339, in <genexpr>
    return (_set_referer(r) for r in result or ())
  File "E:\Users\JohnParker\Anaconda3\lib\site-packages\scrapy\spidermiddlewares\urllength.py", line 37, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "E:\Users\JohnParker\Anaconda3\lib\site-packages\scrapy\spidermiddlewares\depth.py", line 58, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "E:\urlScrapy\urlScrapy\spiders\url_dns.py", line 39, in parse
    mytext = requests.get(page)
  File "E:\Users\JohnParker\Anaconda3\lib\site-packages\requests\api.py", line 72, in get
    return request('get', url, params=params, **kwargs)
  File "E:\Users\JohnParker\Anaconda3\lib\site-packages\requests\api.py", line 58, in request
    return session.request(method=method, url=url, **kwargs)
  File "E:\Users\JohnParker\Anaconda3\lib\site-packages\requests\sessions.py", line 498, in request
    prep = self.prepare_request(req)
  File "E:\Users\JohnParker\Anaconda3\lib\site-packages\requests\sessions.py", line 441, in prepare_request
    hooks=merge_hooks(request.hooks, self.hooks),
  File "E:\Users\JohnParker\Anaconda3\lib\site-packages\requests\models.py", line 309, in prepare
    self.prepare_url(url, params)
  File "E:\Users\JohnParker\Anaconda3\lib\site-packages\requests\models.py", line 377, in prepare_url
    raise InvalidURL(*e.args)
requests.exceptions.InvalidURL: Failed to parse: http: 
2019-Jun-09 16:55:08 retry.py[line:75]/DEBUG/  Retrying <GET http://www.alexa.cn/Soso.com> (failed 1 times): 503 Service Unavailable
2019-Jun-09 16:55:08 middlewares.py[line:19]/DEBUG/  =====  ProxyMiddleware get a random_proxy:【 http://58.22.206.196:9000 】 =====
2019-Jun-09 16:55:12 engine.py[line:238]/DEBUG/  Crawled (200) <GET http://www.alexa.cn/Xinhuanet.com> (referer: http://www.alexa.cn/siterank/)
2019-Jun-09 16:55:12 middlewares.py[line:19]/DEBUG/  =====  ProxyMiddleware get a random_proxy:【 http://1.197.204.6:9999 】 =====
2019-Jun-09 16:55:13 connectionpool.py[line:205]/DEBUG/  Starting new HTTP connection (1): 127.0.0.1:1081
2019-Jun-09 16:55:13 connectionpool.py[line:393]/DEBUG/  http://127.0.0.1:1081 "GET http://www.alexa.cn/api/icp/info?token=551594e57GF3dalpPXlIFmqFTAEioyEEFi-EEgJw72-Gih3yXt5-El3-GwPfcCh7W-EE-K&url=Xinhuanet.com&host=&vcode= HTTP/1.1" 200 None
2019-Jun-09 16:55:13 connectionpool.py[line:205]/DEBUG/  Starting new HTTP connection (1): 127.0.0.1:1081
2019-Jun-09 16:55:13 connectionpool.py[line:393]/DEBUG/  http://127.0.0.1:1081 "GET http://www.alexa.cn/api/server/get?token=390ab8fbceK3JW3WC-B7X-BG8InxhALCJRck0dXsfvveOODGrBtES3-BWKgvQ-BzIpQ-M&url=Xinhuanet.com&force_update=0 HTTP/1.1" 200 None
2019-Jun-09 16:55:13 connectionpool.py[line:205]/DEBUG/  Starting new HTTP connection (1): 127.0.0.1:1081
2019-Jun-09 16:55:13 connectionpool.py[line:393]/DEBUG/  http://127.0.0.1:1081 "GET http://www.alexa.cn/api/who_is/get?token=22f6ea6fMW8rQYbj-JDsntB1RjYZbovRlzSWtHbv91-APc4IXT8ipKweO6Pr7dij0-K&url=Xinhuanet.com&force_update=0 HTTP/1.1" 200 None
2019-Jun-09 16:55:13 connectionpool.py[line:205]/DEBUG/  Starting new HTTP connection (1): 127.0.0.1:1081
2019-Jun-09 16:55:13 connectionpool.py[line:393]/DEBUG/  http://127.0.0.1:1081 "GET http://www.alexa.cn/api/alexa/free?token=e045019c495lgv7-DidEs8fKZQUGqDq6Ay2gO89ra7Z5PuupDwQE6QmZ1Xpkx54E-O&url=Xinhuanet.com HTTP/1.1" 200 None
2019-Jun-09 16:55:13 scraper.py[line:240]/DEBUG/  Scraped from <200 http://www.alexa.cn/Xinhuanet.com>
{'com_name': '新华网股份有限公司',
 'content_type': 'Content-Type: text/html',
 'country_code': 'CN',
 'country_rank': '21',
 'create_day': '2000-04-28',
 'domain': 'xinhuanet.com',
 'http_type': 'HTTP/1.1 200 OK',
 'icp_no': '京ICP证010042号-2',
 'icp_type': '企业',
 'nserver': 'NS1.CDNS.CN',
 'rank_trend_chart': 'http://traffic.alexa.com/graph?o=lt&y=q&b=ffffff&n=666666&f=999999&p=4e8cff&r=1y&t=2&z=0&c=1&h=150&w=340&u=qq.comXinhuanet.com',
 'reg_server': 'BEIJING SANFRONT INFORMATION TECHNOLOGY CO., LTD',
 'search_proportion_chart': 'http://traffic.alexa.com/graph?y=t&b=ffffff&n=666&f=999999&r=7d&t=2&z=30&c=1&h=280&w=920&u=Xinhuanet.com',
 'server': 'WHOIS.SFN.CN',
 'server_ip': '183.131.127.122',
 'server_location': '浙江省台州市',
 'server_type': 'nginx',
 'web_home': 'www.xinhuanet.com',
 'web_name': '新华网',
 'world_rank': '67',
 'world_uv_rank': '77'}
2019-Jun-09 16:55:26 retry.py[line:75]/DEBUG/  Retrying <GET http://www.alexa.cn/Bilibili.com> (failed 1 times): Connection was refused by other side: 10061: 由于目标计算机积极拒绝，无法连接。.
2019-Jun-09 16:55:26 middlewares.py[line:19]/DEBUG/  =====  ProxyMiddleware get a random_proxy:【 http://119.254.94.71:39053 】 =====
2019-Jun-09 16:55:28 engine.py[line:238]/DEBUG/  Crawled (200) <GET http://www.alexa.cn/Alipay.com> (referer: http://www.alexa.cn/siterank/)
2019-Jun-09 16:55:28 middlewares.py[line:19]/DEBUG/  =====  ProxyMiddleware get a random_proxy:【 http://27.188.64.70:8060 】 =====
2019-Jun-09 16:55:28 connectionpool.py[line:205]/DEBUG/  Starting new HTTP connection (1): 127.0.0.1:1081
2019-Jun-09 16:55:28 connectionpool.py[line:393]/DEBUG/  http://127.0.0.1:1081 "GET http://www.alexa.cn/api/icp/info?token=8d2da75d8ZqwirqAJ4Ko-EmhTgAwVka-G0t-E8-GTwXL4TdFcnFb9JrjCwZwROhblhk-O&url=Alipay.com&host=&vcode= HTTP/1.1" 200 None
2019-Jun-09 16:55:28 connectionpool.py[line:205]/DEBUG/  Starting new HTTP connection (1): 127.0.0.1:1081
2019-Jun-09 16:55:28 connectionpool.py[line:393]/DEBUG/  http://127.0.0.1:1081 "GET http://www.alexa.cn/api/server/get?token=66784c38E-AIVBFDz-AbRWCqpgLcDV-I5acNEgGWA1rL-IdrlXIn1k26Uil6qW9clm0-N&url=Alipay.com&force_update=0 HTTP/1.1" 200 None
2019-Jun-09 16:55:28 connectionpool.py[line:205]/DEBUG/  Starting new HTTP connection (1): 127.0.0.1:1081
2019-Jun-09 16:55:29 connectionpool.py[line:393]/DEBUG/  http://127.0.0.1:1081 "GET http://www.alexa.cn/api/who_is/get?token=97f92ef2UvMKAqgkpYd7PsDFkJGOh3RnjjDsrdoj-Im7kmgjBlKtZwLK1066vkZk-L&url=Alipay.com&force_update=0 HTTP/1.1" 200 None
2019-Jun-09 16:55:29 connectionpool.py[line:205]/DEBUG/  Starting new HTTP connection (1): 127.0.0.1:1081
2019-Jun-09 16:55:29 connectionpool.py[line:393]/DEBUG/  http://127.0.0.1:1081 "GET http://www.alexa.cn/api/alexa/free?token=8f876f42ZVk74vcS-DrtEp-FKRS0-DW146bxjQjCFE4IwEDLyPR3UYobYqmip7VkZs-M&url=Alipay.com HTTP/1.1" 200 None
2019-Jun-09 16:55:29 scraper.py[line:240]/DEBUG/  Scraped from <200 http://www.alexa.cn/Alipay.com>
{'com_name': '支付宝（中国）网络技术有限公司',
 'content_type': 'Content-Type: text/html',
 'country_code': 'CN',
 'country_rank': '15',
 'create_day': '2004-10-08',
 'domain': 'alipay.com',
 'http_type': 'HTTP/1.1 301 Moved Permanently',
 'icp_no': '沪ICP备15027489号-2',
 'icp_type': '企业',
 'nserver': 'NS1.ALIPAY.COM',
 'rank_trend_chart': 'http://traffic.alexa.com/graph?o=lt&y=q&b=ffffff&n=666666&f=999999&p=4e8cff&r=1y&t=2&z=0&c=1&h=150&w=340&u=qq.comAlipay.com',
 'reg_server': 'ALIBABA CLOUD COMPUTING (BEIJING) CO., LTD.',
 'search_proportion_chart': 'http://traffic.alexa.com/graph?y=t&b=ffffff&n=666&f=999999&r=7d&t=2&z=30&c=1&h=280&w=920&u=Alipay.com',
 'server': 'GRS-WHOIS.HICHINA.COM',
 'server_ip': '110.75.231.7',
 'server_location': '浙江省杭州市',
 'server_type': 'Tengine/2.1.0',
 'web_home': 'www.alipay.com',
 'web_name': '新支付宝',
 'world_rank': '34',
 'world_uv_rank': '36'}
2019-Jun-09 16:55:37 retry.py[line:75]/DEBUG/  Retrying <GET http://www.alexa.cn/163.com> (failed 1 times): TCP connection timed out: 10060: 由于连接方在一段时间后没有正确答复或连接的主机没有反应，连接尝试失败。.
2019-Jun-09 16:55:37 middlewares.py[line:19]/DEBUG/  =====  ProxyMiddleware get a random_proxy:【 http://180.118.86.237:9999 】 =====
2019-Jun-09 16:55:42 retry.py[line:75]/DEBUG/  Retrying <GET http://www.alexa.cn/Gmw.cn> (failed 1 times): TCP connection timed out: 10060: 由于连接方在一段时间后没有正确答复或连接的主机没有反应，连接尝试失败。.
2019-Jun-09 16:55:42 middlewares.py[line:19]/DEBUG/  =====  ProxyMiddleware get a random_proxy:【 http://1.197.16.95:9999 】 =====
2019-Jun-09 16:55:53 retry.py[line:75]/DEBUG/  Retrying <GET http://www.alexa.cn/Csdn.net> (failed 1 times): TCP connection timed out: 10060: 由于连接方在一段时间后没有正确答复或连接的主机没有反应，连接尝试失败。.
2019-Jun-09 16:55:53 middlewares.py[line:19]/DEBUG/  =====  ProxyMiddleware get a random_proxy:【 http://115.29.3.37:80 】 =====
2019-Jun-09 16:55:54 engine.py[line:238]/DEBUG/  Crawled (200) <GET http://www.alexa.cn/Cnblogs.com> (referer: http://www.alexa.cn/siterank/)
2019-Jun-09 16:55:54 middlewares.py[line:19]/DEBUG/  =====  ProxyMiddleware get a random_proxy:【 http://1.197.204.6:9999 】 =====
2019-Jun-09 16:55:54 connectionpool.py[line:205]/DEBUG/  Starting new HTTP connection (1): 127.0.0.1:1081
2019-Jun-09 16:55:54 connectionpool.py[line:393]/DEBUG/  http://127.0.0.1:1081 "GET http://www.alexa.cn/api/icp/info?token=bd51fb67WckFwVgY9n0ekeErkU8txjwlgYEpceEFCI6lJS02cEqiL4GLWACTXAs-N&url=Cnblogs.com&host=&vcode= HTTP/1.1" 200 None
2019-Jun-09 16:55:54 connectionpool.py[line:205]/DEBUG/  Starting new HTTP connection (1): 127.0.0.1:1081
2019-Jun-09 16:55:55 connectionpool.py[line:393]/DEBUG/  http://127.0.0.1:1081 "GET http://www.alexa.cn/api/server/get?token=9a60e20eoho8U4GWYHYVbmuxhZmJ2wxgJbG1-DLQcG0fms84eW9cv-FFtgnu87FUE-N&url=Cnblogs.com&force_update=0 HTTP/1.1" 200 None
2019-Jun-09 16:55:55 connectionpool.py[line:205]/DEBUG/  Starting new HTTP connection (1): 127.0.0.1:1081
2019-Jun-09 16:55:55 connectionpool.py[line:393]/DEBUG/  http://127.0.0.1:1081 "GET http://www.alexa.cn/api/who_is/get?token=8c7c1eafyWpudKnfuo3IaBe0on-GO28TFtCJeh4cirfjCQx7a-G5l2-G9-DjvGT-Dh9s-N&url=Cnblogs.com&force_update=0 HTTP/1.1" 200 None
2019-Jun-09 16:55:55 connectionpool.py[line:205]/DEBUG/  Starting new HTTP connection (1): 127.0.0.1:1081
2019-Jun-09 16:55:55 connectionpool.py[line:393]/DEBUG/  http://127.0.0.1:1081 "GET http://www.alexa.cn/api/alexa/free?token=b24831c6-IgKRaGAaS2LP7U8T1yoKLu0yQCdAzLWIXOYBrMTyI6R0RfqpOMiHDos-O&url=Cnblogs.com HTTP/1.1" 200 None
2019-Jun-09 16:55:55 scraper.py[line:240]/DEBUG/  Scraped from <200 http://www.alexa.cn/Cnblogs.com>
{'com_name': '上海语程信息科技有限公司',
 'content_type': 'Content-Type: text/html; charset=utf-8',
 'country_code': 'CN',
 'country_rank': '24',
 'create_day': '2003-11-11',
 'domain': 'cnblogs.com',
 'http_type': 'HTTP/1.1 200 OK',
 'icp_no': '沪ICP备09004260号-1',
 'icp_type': '企业',
 'nserver': 'NS3.DNSV4.COM',
 'rank_trend_chart': 'http://traffic.alexa.com/graph?o=lt&y=q&b=ffffff&n=666666&f=999999&p=4e8cff&r=1y&t=2&z=0&c=1&h=150&w=340&u=qq.comCnblogs.com',
 'reg_server': '35 TECHNOLOGY CO., LTD.',
 'search_proportion_chart': 'http://traffic.alexa.com/graph?y=t&b=ffffff&n=666&f=999999&r=7d&t=2&z=30&c=1&h=280&w=920&u=Cnblogs.com',
 'server': 'WHOIS.35.COM',
 'server_ip': '47.96.240.190',
 'server_location': '浙江省杭州市',
 'server_type': '',
 'web_home': 'www.cnweblog.com',
 'web_name': '博客园',
 'world_rank': '78',
 'world_uv_rank': '75'}
2019-Jun-09 16:55:56 engine.py[line:238]/DEBUG/  Crawled (200) <GET http://www.alexa.cn/Hao123.com> (referer: http://www.alexa.cn/siterank/)
2019-Jun-09 16:55:56 middlewares.py[line:19]/DEBUG/  =====  ProxyMiddleware get a random_proxy:【 http://27.188.72.54:8060 】 =====
2019-Jun-09 16:55:57 connectionpool.py[line:205]/DEBUG/  Starting new HTTP connection (1): 127.0.0.1:1081
2019-Jun-09 16:55:57 connectionpool.py[line:393]/DEBUG/  http://127.0.0.1:1081 "GET http://www.alexa.cn/api/icp/info?token=95bd4d8cZvIPLiN6G3PoBpLpHvKX-A6XDamdqwunuA8-AnHNi7w-FHryTBVa8ftrFo-M&url=Hao123.com&host=&vcode= HTTP/1.1" 200 None
2019-Jun-09 16:55:57 connectionpool.py[line:205]/DEBUG/  Starting new HTTP connection (1): 127.0.0.1:1081
2019-Jun-09 16:55:57 connectionpool.py[line:393]/DEBUG/  http://127.0.0.1:1081 "GET http://www.alexa.cn/api/server/get?token=b5cf9e30APF-Alwl42RJGvxg-AR0nE0qVUmT-A5ntgFhcfGsOLTGfm3i6ckJrFEVs4-M&url=Hao123.com&force_update=0 HTTP/1.1" 200 None
2019-Jun-09 16:55:57 connectionpool.py[line:205]/DEBUG/  Starting new HTTP connection (1): 127.0.0.1:1081
2019-Jun-09 16:55:57 connectionpool.py[line:393]/DEBUG/  http://127.0.0.1:1081 "GET http://www.alexa.cn/api/who_is/get?token=0246898cTMRlbJRr1g8MXcjnly6cUr3M6OWXYId5xS-AtvT6eo1jMAqgFbaNua-AI-O&url=Hao123.com&force_update=0 HTTP/1.1" 200 None
2019-Jun-09 16:55:57 connectionpool.py[line:205]/DEBUG/  Starting new HTTP connection (1): 127.0.0.1:1081
2019-Jun-09 16:55:57 connectionpool.py[line:393]/DEBUG/  http://127.0.0.1:1081 "GET http://www.alexa.cn/api/alexa/free?token=b3063ca3OoZHDeqe-J3AwI6JxB9tOGdLCKtnVKCYFeLyX-DjHVNorq1T9KYFpFHzY-M&url=Hao123.com HTTP/1.1" 200 None
2019-Jun-09 16:55:57 scraper.py[line:240]/DEBUG/  Scraped from <200 http://www.alexa.cn/Hao123.com>
{'com_name': '北京百度网讯科技有限公司',
 'content_type': 'Content-Type: text/html;charset=UTF-8',
 'country_code': 'CN',
 'country_rank': '22',
 'create_day': '2000-11-15',
 'domain': 'hao123.com',
 'http_type': 'HTTP/1.1 200 OK',
 'icp_no': '京ICP证030173号-25',
 'icp_type': '企业',
 'nserver': 'DNS.BAIDU.COM',
 'rank_trend_chart': 'http://traffic.alexa.com/graph?o=lt&y=q&b=ffffff&n=666666&f=999999&p=4e8cff&r=1y&t=2&z=0&c=1&h=150&w=340&u=qq.comHao123.com',
 'reg_server': 'MARKMONITOR INC.',
 'search_proportion_chart': 'http://traffic.alexa.com/graph?y=t&b=ffffff&n=666&f=999999&r=7d&t=2&z=30&c=1&h=280&w=920&u=Hao123.com',
 'server': 'WHOIS.MARKMONITOR.COM',
 'server_ip': '115.239.217.167',
 'server_location': '浙江省杭州市',
 'server_type': 'Apache',
 'web_home': 'www.hao123.com',
 'web_name': '网址之家',
 'world_rank': '65',
 'world_uv_rank': '58'}
2019-Jun-09 16:55:57 retry.py[line:75]/DEBUG/  Retrying <GET http://www.alexa.cn/360.cn> (failed 1 times): TCP connection timed out: 10060: 由于连接方在一段时间后没有正确答复或连接的主机没有反应，连接尝试失败。.
2019-Jun-09 16:55:57 middlewares.py[line:19]/DEBUG/  =====  ProxyMiddleware get a random_proxy:【 http://36.250.156.152:9999 】 =====
2019-Jun-09 16:56:01 retry.py[line:75]/DEBUG/  Retrying <GET http://www.alexa.cn/Weibo.com> (failed 1 times): TCP connection timed out: 10060: 由于连接方在一段时间后没有正确答复或连接的主机没有反应，连接尝试失败。.
2019-Jun-09 16:56:01 middlewares.py[line:19]/DEBUG/  =====  ProxyMiddleware get a random_proxy:【 http://119.254.94.71:39053 】 =====
2019-Jun-09 16:56:01 logstats.py[line:48]/INFO/  Crawled 5 pages (at 5 pages/min), scraped 4 items (at 4 items/min)
2019-Jun-09 16:56:05 retry.py[line:75]/DEBUG/  Retrying <GET http://www.alexa.cn/Sina.com.cn> (failed 1 times): TCP connection timed out: 10060: 由于连接方在一段时间后没有正确答复或连接的主机没有反应，连接尝试失败。.
2019-Jun-09 16:56:05 middlewares.py[line:19]/DEBUG/  =====  ProxyMiddleware get a random_proxy:【 http://27.188.64.70:8060 】 =====
2019-Jun-09 16:56:08 retry.py[line:75]/DEBUG/  Retrying <GET http://www.alexa.cn/Babytree.com> (failed 1 times): TCP connection timed out: 10060: 由于连接方在一段时间后没有正确答复或连接的主机没有反应，连接尝试失败。.
2019-Jun-09 16:56:08 middlewares.py[line:19]/DEBUG/  =====  ProxyMiddleware get a random_proxy:【 http://1.197.16.95:9999 】 =====
2019-Jun-09 16:56:11 retry.py[line:75]/DEBUG/  Retrying <GET http://www.alexa.cn/Zhihu.com> (failed 1 times): TCP connection timed out: 10060: 由于连接方在一段时间后没有正确答复或连接的主机没有反应，连接尝试失败。.
2019-Jun-09 16:56:11 middlewares.py[line:19]/DEBUG/  =====  ProxyMiddleware get a random_proxy:【 http://27.188.72.54:8060 】 =====
2019-Jun-09 16:56:21 retry.py[line:75]/DEBUG/  Retrying <GET http://www.alexa.cn/Jd.com> (failed 1 times): TCP connection timed out: 10060: 由于连接方在一段时间后没有正确答复或连接的主机没有反应，连接尝试失败。.
2019-Jun-09 16:56:21 middlewares.py[line:19]/DEBUG/  =====  ProxyMiddleware get a random_proxy:【 http://58.22.206.196:9000 】 =====
2019-Jun-09 16:56:26 retry.py[line:75]/DEBUG/  Retrying <GET http://www.alexa.cn/Sohu.com> (failed 1 times): TCP connection timed out: 10060: 由于连接方在一段时间后没有正确答复或连接的主机没有反应，连接尝试失败。.
2019-Jun-09 16:56:26 middlewares.py[line:19]/DEBUG/  =====  ProxyMiddleware get a random_proxy:【 http://114.230.69.191:9999 】 =====
2019-Jun-09 16:56:26 engine.py[line:238]/DEBUG/  Crawled (200) <GET http://www.alexa.cn/Weibo.com> (referer: http://www.alexa.cn/siterank/)
2019-Jun-09 16:56:26 middlewares.py[line:19]/DEBUG/  =====  ProxyMiddleware get a random_proxy:【 http://180.118.86.237:9999 】 =====
2019-Jun-09 16:56:26 connectionpool.py[line:205]/DEBUG/  Starting new HTTP connection (1): 127.0.0.1:1081
2019-Jun-09 16:56:26 connectionpool.py[line:393]/DEBUG/  http://127.0.0.1:1081 "GET http://www.alexa.cn/api/icp/info?token=e5c53200CnkqMlTw3ltqfxoCaBD1-IOBoH076qNtm9pVRaRSKql-IKi0Ud9KNhFQw-N&url=Weibo.com&host=&vcode= HTTP/1.1" 200 None
2019-Jun-09 16:56:26 connectionpool.py[line:205]/DEBUG/  Starting new HTTP connection (1): 127.0.0.1:1081
2019-Jun-09 16:56:26 connectionpool.py[line:393]/DEBUG/  http://127.0.0.1:1081 "GET http://www.alexa.cn/api/server/get?token=77a64cfcinFeGUPJp5sfeWnImac5FC-EFnPlnBH3Pix3l1RVJa7xCEsGtadhp79k-L&url=Weibo.com&force_update=0 HTTP/1.1" 200 None
2019-Jun-09 16:56:26 connectionpool.py[line:205]/DEBUG/  Starting new HTTP connection (1): 127.0.0.1:1081
2019-Jun-09 16:56:26 connectionpool.py[line:393]/DEBUG/  http://127.0.0.1:1081 "GET http://www.alexa.cn/api/who_is/get?token=bee1cdcb523qIe8j5VMbtXlAeil2wd8UcddTc5iMRJrEATBDUM3dE4PVjgglYwI-K&url=Weibo.com&force_update=0 HTTP/1.1" 200 None
2019-Jun-09 16:56:26 connectionpool.py[line:205]/DEBUG/  Starting new HTTP connection (1): 127.0.0.1:1081
2019-Jun-09 16:56:26 connectionpool.py[line:393]/DEBUG/  http://127.0.0.1:1081 "GET http://www.alexa.cn/api/alexa/free?token=dae8d958oZKVZ4SLrpk1uShpRnzZclz9QywWDmPNiPl7pQQxjFUGAJ5ytibHoWk-O&url=Weibo.com HTTP/1.1" 200 None
2019-Jun-09 16:56:26 scraper.py[line:240]/DEBUG/  Scraped from <200 http://www.alexa.cn/Weibo.com>
{'com_name': '北京微梦创科网络技术有限公司',
 'content_type': 'Content-Type: text/html',
 'country_code': 'CN',
 'country_rank': '8',
 'create_day': '1999-03-20',
 'domain': 'weibo.com',
 'http_type': 'HTTP/1.1 301 Moved Permanently',
 'icp_no': '京ICP备12002058号-2',
 'icp_type': '企业',
 'nserver': 'NS1.SINA.COM.CN',
 'rank_trend_chart': 'http://traffic.alexa.com/graph?o=lt&y=q&b=ffffff&n=666666&f=999999&p=4e8cff&r=1y&t=2&z=0&c=1&h=150&w=340&u=qq.comWeibo.com',
 'reg_server': 'XIAMEN 35.COM TECHNOLOGY CO., LTD.',
 'search_proportion_chart': 'http://traffic.alexa.com/graph?y=t&b=ffffff&n=666&f=999999&r=7d&t=2&z=30&c=1&h=280&w=920&u=Weibo.com',
 'server': 'WHOIS.35.COM',
 'server_ip': '180.149.134.142',
 'server_location': '北京市',
 'server_type': 'WeiBo',
 'web_home': 'www.weibo.com',
 'web_name': '微博平台',
 'world_rank': '17',
 'world_uv_rank': '18'}
2019-Jun-09 16:56:29 engine.py[line:238]/DEBUG/  Crawled (200) <GET http://www.alexa.cn/Sina.com.cn> (referer: http://www.alexa.cn/siterank/)
2019-Jun-09 16:56:29 middlewares.py[line:19]/DEBUG/  =====  ProxyMiddleware get a random_proxy:【 http://119.254.94.71:39053 】 =====
2019-Jun-09 16:56:29 connectionpool.py[line:205]/DEBUG/  Starting new HTTP connection (1): 127.0.0.1:1081
2019-Jun-09 16:56:29 connectionpool.py[line:393]/DEBUG/  http://127.0.0.1:1081 "GET http://www.alexa.cn/api/icp/info?token=b381b5ffRoBYrxBTabO6U1YNKH5en7cu-DEwQAYSFAbalecHM2IQEEQzT7hftIQI-O&url=Sina.com.cn&host=&vcode= HTTP/1.1" 200 None
2019-Jun-09 16:56:29 connectionpool.py[line:205]/DEBUG/  Starting new HTTP connection (1): 127.0.0.1:1081
2019-Jun-09 16:56:29 connectionpool.py[line:393]/DEBUG/  http://127.0.0.1:1081 "GET http://www.alexa.cn/api/server/get?token=6c940e81YN4hcfM7wU0Wsk1snyKj-DRxi9FSg2EEaah3vIuPCGdL4CHd0s2y7Aj4-M&url=Sina.com.cn&force_update=0 HTTP/1.1" 200 None
2019-Jun-09 16:56:29 connectionpool.py[line:205]/DEBUG/  Starting new HTTP connection (1): 127.0.0.1:1081
2019-Jun-09 16:56:30 connectionpool.py[line:393]/DEBUG/  http://127.0.0.1:1081 "GET http://www.alexa.cn/api/who_is/get?token=a69dc8dbU2-JgDwxyOpDlO68H7pgqnfn6dcW0q70-AMnTlLhYBjOx279pIoM-AiIEE-L&url=Sina.com.cn&force_update=0 HTTP/1.1" 200 None
2019-Jun-09 16:56:30 connectionpool.py[line:205]/DEBUG/  Starting new HTTP connection (1): 127.0.0.1:1081
2019-Jun-09 16:56:30 connectionpool.py[line:393]/DEBUG/  http://127.0.0.1:1081 "GET http://www.alexa.cn/api/alexa/free?token=0f2405a3Co9XFZ3PxMxKCiEErlz3QbTdfjk5qk5YQvKoOIVC8eQCayMGHg7Y7Xo-N&url=Sina.com.cn HTTP/1.1" 200 None
2019-Jun-09 16:56:30 scraper.py[line:240]/DEBUG/  Scraped from <200 http://www.alexa.cn/Sina.com.cn>
{'com_name': '北京新浪互联信息服务有限公司',
 'content_type': 'Content-Type: text/html',
 'country_code': 'CN',
 'country_rank': '7',
 'create_day': '1998-11-20',
 'domain': 'sina.com.cn',
 'http_type': 'HTTP/1.1 302 Moved Temporarily',
 'icp_no': '京ICP证000007-6',
 'icp_type': '企业',
 'nserver': 'ns3.sina.com.cn',
 'rank_trend_chart': 'http://traffic.alexa.com/graph?o=lt&y=q&b=ffffff&n=666666&f=999999&p=4e8cff&r=1y&t=2&z=0&c=1&h=150&w=340&u=qq.comSina.com.cn',
 'reg_server': '北京新网数码信息技术有限公司',
 'search_proportion_chart': 'http://traffic.alexa.com/graph?y=t&b=ffffff&n=666&f=999999&r=7d&t=2&z=30&c=1&h=280&w=920&u=Sina.com.cn',
 'server': 'WHOIS.CNNIC.CN',
 'server_ip': '115.238.190.239',
 'server_location': '浙江省宁波市',
 'server_type': 'nginx',
 'web_home': 'www.sina.com.cn',
 'web_name': '新浪网',
 'world_rank': '16',
 'world_uv_rank': '16'}
2019-Jun-09 16:56:30 retry.py[line:75]/DEBUG/  Retrying <GET http://www.alexa.cn/Tmall.com> (failed 1 times): TCP connection timed out: 10060: 由于连接方在一段时间后没有正确答复或连接的主机没有反应，连接尝试失败。.
2019-Jun-09 16:56:30 middlewares.py[line:19]/DEBUG/  =====  ProxyMiddleware get a random_proxy:【 http://119.254.94.71:39053 】 =====
2019-Jun-09 16:56:34 retry.py[line:75]/DEBUG/  Retrying <GET http://www.alexa.cn/Taobao.com> (failed 1 times): TCP connection timed out: 10060: 由于连接方在一段时间后没有正确答复或连接的主机没有反应，连接尝试失败。.
2019-Jun-09 16:56:34 middlewares.py[line:19]/DEBUG/  =====  ProxyMiddleware get a random_proxy:【 http://101.200.50.18:8118 】 =====
2019-Jun-09 16:56:38 retry.py[line:75]/DEBUG/  Retrying <GET http://www.alexa.cn/Qq.com> (failed 1 times): TCP connection timed out: 10060: 由于连接方在一段时间后没有正确答复或连接的主机没有反应，连接尝试失败。.
2019-Jun-09 16:56:38 middlewares.py[line:19]/DEBUG/  =====  ProxyMiddleware get a random_proxy:【 http://114.230.69.191:9999 】 =====
2019-Jun-09 16:56:42 retry.py[line:75]/DEBUG/  Retrying <GET http://www.alexa.cn/Baidu.com> (failed 1 times): TCP connection timed out: 10060: 由于连接方在一段时间后没有正确答复或连接的主机没有反应，连接尝试失败。.
2019-Jun-09 16:56:42 middlewares.py[line:19]/DEBUG/  =====  ProxyMiddleware get a random_proxy:【 http://1.197.204.6:9999 】 =====
2019-Jun-09 16:56:44 engine.py[line:238]/DEBUG/  Crawled (200) <GET http://www.alexa.cn/Zhihu.com> (referer: http://www.alexa.cn/siterank/)
2019-Jun-09 16:56:44 middlewares.py[line:19]/DEBUG/  =====  ProxyMiddleware get a random_proxy:【 http://114.230.69.191:9999 】 =====
2019-Jun-09 16:56:44 connectionpool.py[line:205]/DEBUG/  Starting new HTTP connection (1): 127.0.0.1:1081
2019-Jun-09 16:56:44 connectionpool.py[line:393]/DEBUG/  http://127.0.0.1:1081 "GET http://www.alexa.cn/api/icp/info?token=bf1920298VMg5nXwAih8u-HNsPvyue4zKKNzr74T226gX9xpI9Ub8nYs9T8UexP0-L&url=Zhihu.com&host=&vcode= HTTP/1.1" 200 None
2019-Jun-09 16:56:44 connectionpool.py[line:205]/DEBUG/  Starting new HTTP connection (1): 127.0.0.1:1081
2019-Jun-09 16:56:44 connectionpool.py[line:393]/DEBUG/  http://127.0.0.1:1081 "GET http://www.alexa.cn/api/server/get?token=8e343caa654vg6hOGktp4xswD5RobNTR85jiP5-BCrmOD6E5Qojb-H5ern45uwbZ4-N&url=Zhihu.com&force_update=0 HTTP/1.1" 200 None
2019-Jun-09 16:56:44 connectionpool.py[line:205]/DEBUG/  Starting new HTTP connection (1): 127.0.0.1:1081
2019-Jun-09 16:56:45 connectionpool.py[line:393]/DEBUG/  http://127.0.0.1:1081 "GET http://www.alexa.cn/api/who_is/get?token=cd8fe8c7BWNH6gi0SE-AmkEGYuRxf4LvfeONznjGTGqNPN9JuUdHB1E3u7ZCBnfM-K&url=Zhihu.com&force_update=0 HTTP/1.1" 200 None
2019-Jun-09 16:56:45 connectionpool.py[line:205]/DEBUG/  Starting new HTTP connection (1): 127.0.0.1:1081
2019-Jun-09 16:56:45 connectionpool.py[line:393]/DEBUG/  http://127.0.0.1:1081 "GET http://www.alexa.cn/api/alexa/free?token=9175c835BzAxFcZ47QJmDrhZGzWe4N7joKBYLowHc6J5WTAcwPowJ68q3yWPQvI-O&url=Zhihu.com HTTP/1.1" 200 None
2019-Jun-09 16:56:45 scraper.py[line:240]/DEBUG/  Scraped from <200 http://www.alexa.cn/Zhihu.com>
{'com_name': '北京智者天下科技有限公司',
 'content_type': 'Content-Type: text/html',
 'country_code': 'CN',
 'country_rank': '25',
 'create_day': '2007-06-16',
 'domain': 'zhihu.com',
 'http_type': 'HTTP/1.1 301 Moved Permanently',
 'icp_no': '京ICP备13052560号-1',
 'icp_type': '企业',
 'nserver': 'NS3.DNSV5.COM',
 'rank_trend_chart': 'http://traffic.alexa.com/graph?o=lt&y=q&b=ffffff&n=666666&f=999999&p=4e8cff&r=1y&t=2&z=0&c=1&h=150&w=340&u=qq.comZhihu.com',
 'reg_server': 'GODADDY.COM, LLC',
 'search_proportion_chart': 'http://traffic.alexa.com/graph?y=t&b=ffffff&n=666&f=999999&r=7d&t=2&z=30&c=1&h=280&w=920&u=Zhihu.com',
 'server': 'WHOIS.GODADDY.COM',
 'server_ip': '118.89.204.190',
 'server_location': '天津市滨海新区',
 'server_type': 'ZWS',
 'web_home': 'www.zhihu.com',
 'web_name': '知乎',
 'world_rank': '82',
 'world_uv_rank': '81'}
2019-Jun-09 16:56:48 retry.py[line:75]/DEBUG/  Retrying <GET http://www.alexa.cn/Sohu.com> (failed 2 times): Connection was refused by other side: 10061: 由于目标计算机积极拒绝，无法连接。.
2019-Jun-09 16:56:48 middlewares.py[line:19]/DEBUG/  =====  ProxyMiddleware get a random_proxy:【 http://1.197.204.6:9999 】 =====
2019-Jun-09 16:56:53 engine.py[line:238]/DEBUG/  Crawled (200) <GET http://www.alexa.cn/Csdn.net> (referer: http://www.alexa.cn/siterank/)
2019-Jun-09 16:56:53 middlewares.py[line:19]/DEBUG/  =====  ProxyMiddleware get a random_proxy:【 http://115.29.3.37:80 】 =====
2019-Jun-09 16:56:53 connectionpool.py[line:205]/DEBUG/  Starting new HTTP connection (1): 127.0.0.1:1081
2019-Jun-09 16:56:53 connectionpool.py[line:393]/DEBUG/  http://127.0.0.1:1081 "GET http://www.alexa.cn/api/icp/info?token=3cbca56bXEnRdF008s5z7A5NJofWTK-CG6HcfSDBWZ1hDwtgQvNKHDq0CB20OKvc-K&url=Csdn.net&host=&vcode= HTTP/1.1" 200 None
2019-Jun-09 16:56:53 connectionpool.py[line:205]/DEBUG/  Starting new HTTP connection (1): 127.0.0.1:1081
2019-Jun-09 16:56:54 connectionpool.py[line:393]/DEBUG/  http://127.0.0.1:1081 "GET http://www.alexa.cn/api/server/get?token=140656bf6ifqvNjirGqtONKPFkCyqlmJah-FdUUcF8R5d-CpW7d7k05in9-CR1g9Bg-O&url=Csdn.net&force_update=0 HTTP/1.1" 200 None
2019-Jun-09 16:56:54 connectionpool.py[line:205]/DEBUG/  Starting new HTTP connection (1): 127.0.0.1:1081
2019-Jun-09 16:56:54 connectionpool.py[line:393]/DEBUG/  http://127.0.0.1:1081 "GET http://www.alexa.cn/api/who_is/get?token=a4f148baC-EMAZBmOabce6QvZyMFAoc7OzH2qHQcpO3sQzyjYEtyRsFBjhKz-IUO4-L&url=Csdn.net&force_update=0 HTTP/1.1" 200 None
2019-Jun-09 16:56:54 connectionpool.py[line:205]/DEBUG/  Starting new HTTP connection (1): 127.0.0.1:1081
2019-Jun-09 16:56:54 connectionpool.py[line:393]/DEBUG/  http://127.0.0.1:1081 "GET http://www.alexa.cn/api/alexa/free?token=e2d238beEI7cJUr6BWLoywcF74I-Admr4UUeilPnbN1feSkwZEn67aIQ4Y-AdwzN4-N&url=Csdn.net HTTP/1.1" 200 None
2019-Jun-09 16:56:54 scraper.py[line:240]/DEBUG/  Scraped from <200 http://www.alexa.cn/Csdn.net>
{'com_name': '北京创新乐知信息技术有限公司',
 'content_type': 'Content-Type: text/html',
 'country_code': 'CN',
 'country_rank': '13',
 'create_day': '1999-03-11',
 'domain': 'csdn.net',
 'http_type': 'HTTP/1.1 301 Moved Permanently',
 'icp_no': '京ICP备09002463号-6',
 'icp_type': '企业',
 'nserver': 'VIP3.ALIDNS.COM',
 'rank_trend_chart': 'http://traffic.alexa.com/graph?o=lt&y=q&b=ffffff&n=666666&f=999999&p=4e8cff&r=1y&t=2&z=0&c=1&h=150&w=340&u=qq.comCsdn.net',
 'reg_server': 'ALIBABA CLOUD COMPUTING (BEIJING) CO., LTD.',
 'search_proportion_chart': 'http://traffic.alexa.com/graph?y=t&b=ffffff&n=666&f=999999&r=7d&t=2&z=30&c=1&h=280&w=920&u=Csdn.net',
 'server': 'GRS-WHOIS.HICHINA.COM',
 'server_ip': '47.95.164.112',
 'server_location': '北京市',
 'server_type': 'openresty',
 'web_home': 'www.csdn.net',
 'web_name': 'CSDN软件开发网',
 'world_rank': '28',
 'world_uv_rank': '35'}
2019-Jun-09 16:56:54 retry.py[line:75]/DEBUG/  Retrying <GET http://www.alexa.cn/Babytree.com> (failed 2 times): TCP connection timed out: 10060: 由于连接方在一段时间后没有正确答复或连接的主机没有反应，连接尝试失败。.
2019-Jun-09 16:56:54 middlewares.py[line:19]/DEBUG/  =====  ProxyMiddleware get a random_proxy:【 http://114.227.154.184:9999 】 =====
2019-Jun-09 16:56:55 retry.py[line:75]/DEBUG/  Retrying <GET http://www.alexa.cn/Taobao.com> (failed 2 times): 503 Service Unavailable
2019-Jun-09 16:56:55 middlewares.py[line:19]/DEBUG/  =====  ProxyMiddleware get a random_proxy:【 http://119.254.94.71:39053 】 =====
2019-Jun-09 16:56:59 retry.py[line:75]/DEBUG/  Retrying <GET http://www.alexa.cn/Jd.com> (failed 2 times): TCP connection timed out: 10060: 由于连接方在一段时间后没有正确答复或连接的主机没有反应，连接尝试失败。.
2019-Jun-09 16:56:59 middlewares.py[line:19]/DEBUG/  =====  ProxyMiddleware get a random_proxy:【 http://180.118.86.237:9999 】 =====
2019-Jun-09 16:57:01 logstats.py[line:48]/INFO/  Crawled 9 pages (at 4 pages/min), scraped 8 items (at 4 items/min)
2019-Jun-09 16:57:05 retry.py[line:75]/DEBUG/  Retrying <GET http://www.alexa.cn/Qq.com> (failed 2 times): Connection was refused by other side: 10061: 由于目标计算机积极拒绝，无法连接。.
2019-Jun-09 16:57:05 middlewares.py[line:19]/DEBUG/  =====  ProxyMiddleware get a random_proxy:【 http://115.29.3.37:80 】 =====
2019-Jun-09 16:57:06 retry.py[line:75]/DEBUG/  Retrying <GET http://www.alexa.cn/360.cn> (failed 2 times): TCP connection timed out: 10060: 由于连接方在一段时间后没有正确答复或连接的主机没有反应，连接尝试失败。.
2019-Jun-09 16:57:06 middlewares.py[line:19]/DEBUG/  =====  ProxyMiddleware get a random_proxy:【 http://113.110.45.45:9999 】 =====
2019-Jun-09 16:57:14 retry.py[line:75]/DEBUG/  Retrying <GET http://www.alexa.cn/Tmall.com> (failed 2 times): TCP connection timed out: 10060: 由于连接方在一段时间后没有正确答复或连接的主机没有反应，连接尝试失败。.
2019-Jun-09 16:57:14 middlewares.py[line:19]/DEBUG/  =====  ProxyMiddleware get a random_proxy:【 http://115.29.3.37:80 】 =====
2019-Jun-09 16:57:23 retry.py[line:75]/DEBUG/  Retrying <GET http://www.alexa.cn/Baidu.com> (failed 2 times): TCP connection timed out: 10060: 由于连接方在一段时间后没有正确答复或连接的主机没有反应，连接尝试失败。.
2019-Jun-09 16:57:24 middlewares.py[line:19]/DEBUG/  =====  ProxyMiddleware get a random_proxy:【 http://27.188.72.54:8060 】 =====
2019-Jun-09 16:57:28 retry.py[line:75]/DEBUG/  Retrying <GET http://www.alexa.cn/Gmw.cn> (failed 2 times): TCP connection timed out: 10060: 由于连接方在一段时间后没有正确答复或连接的主机没有反应，连接尝试失败。.
2019-Jun-09 16:57:28 middlewares.py[line:19]/DEBUG/  =====  ProxyMiddleware get a random_proxy:【 http://36.250.156.152:9999 】 =====
2019-Jun-09 16:57:32 retry.py[line:75]/DEBUG/  Retrying <GET http://www.alexa.cn/163.com> (failed 2 times): TCP connection timed out: 10060: 由于连接方在一段时间后没有正确答复或连接的主机没有反应，连接尝试失败。.
2019-Jun-09 16:57:32 middlewares.py[line:19]/DEBUG/  =====  ProxyMiddleware get a random_proxy:【 http://1.197.204.6:9999 】 =====
2019-Jun-09 16:57:35 retry.py[line:75]/DEBUG/  Retrying <GET http://www.alexa.cn/Bilibili.com> (failed 2 times): TCP connection timed out: 10060: 由于连接方在一段时间后没有正确答复或连接的主机没有反应，连接尝试失败。.
2019-Jun-09 16:57:35 middlewares.py[line:19]/DEBUG/  =====  ProxyMiddleware get a random_proxy:【 http://121.232.148.197:9000 】 =====
2019-Jun-09 16:57:39 retry.py[line:75]/DEBUG/  Retrying <GET http://www.alexa.cn/Soso.com> (failed 2 times): TCP connection timed out: 10060: 由于连接方在一段时间后没有正确答复或连接的主机没有反应，连接尝试失败。.
2019-Jun-09 16:57:39 middlewares.py[line:19]/DEBUG/  =====  ProxyMiddleware get a random_proxy:【 http://1.197.204.6:9999 】 =====
2019-Jun-09 16:57:42 retry.py[line:91]/DEBUG/  Gave up retrying <GET http://www.alexa.cn/Baidu.com> (failed 3 times): 500 Internal Server Error
2019-Jun-09 16:57:42 engine.py[line:238]/DEBUG/  Crawled (500) <GET http://www.alexa.cn/Baidu.com> (referer: http://www.alexa.cn/siterank/)
2019-Jun-09 16:57:42 middlewares.py[line:19]/DEBUG/  =====  ProxyMiddleware get a random_proxy:【 http://121.232.148.197:9000 】 =====
2019-Jun-09 16:57:42 httperror.py[line:55]/INFO/  Ignoring response <500 http://www.alexa.cn/Baidu.com>: HTTP status code is not handled or not allowed
2019-Jun-09 16:57:46 engine.py[line:238]/DEBUG/  Crawled (200) <GET http://www.alexa.cn/Tmall.com> (referer: http://www.alexa.cn/siterank/)
2019-Jun-09 16:57:46 middlewares.py[line:19]/DEBUG/  =====  ProxyMiddleware get a random_proxy:【 http://58.22.206.196:9000 】 =====
2019-Jun-09 16:57:46 connectionpool.py[line:205]/DEBUG/  Starting new HTTP connection (1): 127.0.0.1:1081
2019-Jun-09 16:57:46 connectionpool.py[line:393]/DEBUG/  http://127.0.0.1:1081 "GET http://www.alexa.cn/api/icp/info?token=a6a53d96FlkV0ONtgKTacBMUcTRJzeBih5q-ElqDgst9pcmq4-EB3-JvVH2tlel-JPE-K&url=Tmall.com&host=&vcode= HTTP/1.1" 200 None
2019-Jun-09 16:57:46 connectionpool.py[line:205]/DEBUG/  Starting new HTTP connection (1): 127.0.0.1:1081
2019-Jun-09 16:57:46 connectionpool.py[line:393]/DEBUG/  http://127.0.0.1:1081 "GET http://www.alexa.cn/api/server/get?token=a735f146e6hABusvU23X2LTbQSt6jYpzAUsF9eEaxHIzRz0-ISHj6CCxmkSqrsSM-M&url=Tmall.com&force_update=0 HTTP/1.1" 200 None
2019-Jun-09 16:57:46 connectionpool.py[line:205]/DEBUG/  Starting new HTTP connection (1): 127.0.0.1:1081
2019-Jun-09 16:57:46 connectionpool.py[line:393]/DEBUG/  http://127.0.0.1:1081 "GET http://www.alexa.cn/api/who_is/get?token=ac6c858dihois06OMvMQR-FZqk6qdwf-F9jpmrFSqvuw7sJBljLKu9zJGZ-D6GmKh0-K&url=Tmall.com&force_update=0 HTTP/1.1" 200 None
2019-Jun-09 16:57:46 connectionpool.py[line:205]/DEBUG/  Starting new HTTP connection (1): 127.0.0.1:1081
2019-Jun-09 16:57:46 connectionpool.py[line:393]/DEBUG/  http://127.0.0.1:1081 "GET http://www.alexa.cn/api/alexa/free?token=f65e2f93u3nXfqX9D0CFP7v22-ES2LyafHQ9tVdTdhOVSayiyXND9y4W4tA-E-JSrc-M&url=Tmall.com HTTP/1.1" 200 None
2019-Jun-09 16:57:47 scraper.py[line:240]/DEBUG/  Scraped from <200 http://www.alexa.cn/Tmall.com>
{'com_name': '浙江天猫网络有限公司',
 'content_type': 'Content-Type: text/html',
 'country_code': 'CN',
 'country_rank': '4',
 'create_day': '1997-10-17',
 'domain': 'tmall.com',
 'http_type': 'HTTP/1.1 302 Found',
 'icp_no': '浙B2-20110446-1',
 'icp_type': '企业',
 'nserver': 'NS4.TAOBAO.COM',
 'rank_trend_chart': 'http://traffic.alexa.com/graph?o=lt&y=q&b=ffffff&n=666666&f=999999&p=4e8cff&r=1y&t=2&z=0&c=1&h=150&w=340&u=qq.comTmall.com',
 'reg_server': 'ALIBABA CLOUD COMPUTING (BEIJING) CO., LTD.',
 'search_proportion_chart': 'http://traffic.alexa.com/graph?y=t&b=ffffff&n=666&f=999999&r=7d&t=2&z=30&c=1&h=280&w=920&u=Tmall.com',
 'server': 'GRS-WHOIS.HICHINA.COM',
 'server_ip': '101.37.183.170',
 'server_location': '浙江省杭州市',
 'server_type': 'Tengine',
 'web_home': 'www.tmall.com',
 'web_name': '天猫',
 'world_rank': '8',
 'world_uv_rank': '7'}
2019-Jun-09 16:57:47 retry.py[line:91]/DEBUG/  Gave up retrying <GET http://www.alexa.cn/Taobao.com> (failed 3 times): [<twisted.python.failure.Failure twisted.internet.error.ConnectionLost: Connection to the other side was lost in a non-clean fashion.>]
2019-Jun-09 16:57:47 proxyDBManager.py[line:181]/DEBUG/  ===  success to update 119.254.94.71 proxy  ===
2019-Jun-09 16:57:47 proxyDBManager.py[line:181]/DEBUG/  ===  success to update 119.254.94.71 proxy  ===
2019-Jun-09 16:57:48 scraper.py[line:208]/ERROR/  Error downloading <GET http://www.alexa.cn/Taobao.com>
Traceback (most recent call last):
  File "E:\Users\JohnParker\Anaconda3\lib\site-packages\scrapy\core\downloader\middleware.py", line 43, in process_request
    defer.returnValue((yield download_func(request=request,spider=spider)))
twisted.web._newclient.ResponseNeverReceived: [<twisted.python.failure.Failure twisted.internet.error.ConnectionLost: Connection to the other side was lost in a non-clean fashion.>]
2019-Jun-09 16:57:48 retry.py[line:91]/DEBUG/  Gave up retrying <GET http://www.alexa.cn/Jd.com> (failed 3 times): TCP connection timed out: 10060: 由于连接方在一段时间后没有正确答复或连接的主机没有反应，连接尝试失败。.
2019-Jun-09 16:57:48 proxyDBManager.py[line:181]/DEBUG/  ===  success to update 180.118.86.237 proxy  ===
2019-Jun-09 16:57:48 proxyDBManager.py[line:181]/DEBUG/  ===  success to update 180.118.86.237 proxy  ===
2019-Jun-09 16:57:48 engine.py[line:238]/DEBUG/  Crawled (200) <GET http://www.alexa.cn/Qq.com> (referer: http://www.alexa.cn/siterank/)
2019-Jun-09 16:57:48 scraper.py[line:208]/ERROR/  Error downloading <GET http://www.alexa.cn/Jd.com>
Traceback (most recent call last):
  File "E:\Users\JohnParker\Anaconda3\lib\site-packages\scrapy\core\downloader\middleware.py", line 43, in process_request
    defer.returnValue((yield download_func(request=request,spider=spider)))
twisted.internet.error.TCPTimedOutError: TCP connection timed out: 10060: 由于连接方在一段时间后没有正确答复或连接的主机没有反应，连接尝试失败。.
2019-Jun-09 16:57:48 connectionpool.py[line:205]/DEBUG/  Starting new HTTP connection (1): 127.0.0.1:1081
2019-Jun-09 16:57:49 connectionpool.py[line:393]/DEBUG/  http://127.0.0.1:1081 "GET http://www.alexa.cn/api/icp/info?token=a408c26dBeiIfdhudOcwLpBLDwjy8L8VhVZJEAYSU91VxnN7CMyykl1jU3RxgMw-K&url=Qq.com&host=&vcode= HTTP/1.1" 200 None
2019-Jun-09 16:57:49 connectionpool.py[line:205]/DEBUG/  Starting new HTTP connection (1): 127.0.0.1:1081
2019-Jun-09 16:57:49 connectionpool.py[line:393]/DEBUG/  http://127.0.0.1:1081 "GET http://www.alexa.cn/api/server/get?token=4c3e771cT1URlIAIUGhfLKon22eb3vajdzF8v1RekgnZKwYEGlvg-B0PhTDDV7fg-O&url=Qq.com&force_update=0 HTTP/1.1" 200 None
2019-Jun-09 16:57:49 connectionpool.py[line:205]/DEBUG/  Starting new HTTP connection (1): 127.0.0.1:1081
2019-Jun-09 16:57:49 connectionpool.py[line:393]/DEBUG/  http://127.0.0.1:1081 "GET http://www.alexa.cn/api/who_is/get?token=25bba63a9hrB0afUXmvbE7LmQM4KxKzYR7r8p4jsyp5K2LYSBGvZUb4rxDsw5xA-L&url=Qq.com&force_update=0 HTTP/1.1" 200 None
2019-Jun-09 16:57:49 connectionpool.py[line:205]/DEBUG/  Starting new HTTP connection (1): 127.0.0.1:1081
2019-Jun-09 16:57:49 connectionpool.py[line:393]/DEBUG/  http://127.0.0.1:1081 "GET http://www.alexa.cn/api/alexa/free?token=511accf0vILdXAa81Gg1bysWJ5dzjt69FRbDIMesWoCyQBBCjWGJyUXw4-Fy-FRYU-K&url=Qq.com HTTP/1.1" 200 None
2019-Jun-09 16:57:49 scraper.py[line:240]/DEBUG/  Scraped from <200 http://www.alexa.cn/Qq.com>
{'com_name': '深圳市腾讯计算机系统有限公司',
 'content_type': 'Content-Type: text/html',
 'country_code': 'CN',
 'country_rank': '2',
 'create_day': '1995-05-04',
 'domain': 'qq.com',
 'http_type': 'HTTP/1.1 302 Moved Temporarily',
 'icp_no': '粤B2-20090059-5',
 'icp_type': '企业',
 'nserver': 'NS1.QQ.COM',
 'rank_trend_chart': 'http://traffic.alexa.com/graph?o=lt&y=q&b=ffffff&n=666666&f=999999&p=4e8cff&r=1y&t=2&z=0&c=1&h=150&w=340&u=qq.comQq.com',
 'reg_server': 'MARKMONITOR INC.',
 'search_proportion_chart': 'http://traffic.alexa.com/graph?y=t&b=ffffff&n=666&f=999999&r=7d&t=2&z=30&c=1&h=280&w=920&u=Qq.com',
 'server': 'WHOIS.MARKMONITOR.COM',
 'server_ip': '58.250.137.36',
 'server_location': '广东省深圳市',
 'server_type': 'stgw/1.3.10.6_1.13.5',
 'web_home': 'www.qq.com',
 'web_name': '腾讯网',
 'world_rank': '6',
 'world_uv_rank': '6'}
2019-Jun-09 16:57:55 retry.py[line:91]/DEBUG/  Gave up retrying <GET http://www.alexa.cn/360.cn> (failed 3 times): TCP connection timed out: 10060: 由于连接方在一段时间后没有正确答复或连接的主机没有反应，连接尝试失败。.
2019-Jun-09 16:57:56 proxyDBManager.py[line:181]/DEBUG/  ===  success to update 113.110.45.45 proxy  ===
2019-Jun-09 16:57:56 proxyDBManager.py[line:181]/DEBUG/  ===  success to update 113.110.45.45 proxy  ===
2019-Jun-09 16:57:56 scraper.py[line:208]/ERROR/  Error downloading <GET http://www.alexa.cn/360.cn>
Traceback (most recent call last):
  File "E:\Users\JohnParker\Anaconda3\lib\site-packages\scrapy\core\downloader\middleware.py", line 43, in process_request
    defer.returnValue((yield download_func(request=request,spider=spider)))
twisted.internet.error.TCPTimedOutError: TCP connection timed out: 10060: 由于连接方在一段时间后没有正确答复或连接的主机没有反应，连接尝试失败。.
2019-Jun-09 16:58:00 retry.py[line:91]/DEBUG/  Gave up retrying <GET http://www.alexa.cn/Bilibili.com> (failed 3 times): Connection was refused by other side: 10061: 由于目标计算机积极拒绝，无法连接。.
2019-Jun-09 16:58:00 proxyDBManager.py[line:181]/DEBUG/  ===  success to update 121.232.148.197 proxy  ===
2019-Jun-09 16:58:00 proxyDBManager.py[line:181]/DEBUG/  ===  success to update 121.232.148.197 proxy  ===
2019-Jun-09 16:58:00 scraper.py[line:208]/ERROR/  Error downloading <GET http://www.alexa.cn/Bilibili.com>
Traceback (most recent call last):
  File "E:\Users\JohnParker\Anaconda3\lib\site-packages\scrapy\core\downloader\middleware.py", line 43, in process_request
    defer.returnValue((yield download_func(request=request,spider=spider)))
twisted.internet.error.ConnectionRefusedError: Connection was refused by other side: 10061: 由于目标计算机积极拒绝，无法连接。.
2019-Jun-09 16:58:01 logstats.py[line:48]/INFO/  Crawled 12 pages (at 3 pages/min), scraped 10 items (at 2 items/min)
2019-Jun-09 16:58:06 retry.py[line:91]/DEBUG/  Gave up retrying <GET http://www.alexa.cn/Gmw.cn> (failed 3 times): TCP connection timed out: 10060: 由于连接方在一段时间后没有正确答复或连接的主机没有反应，连接尝试失败。.
2019-Jun-09 16:58:06 proxyDBManager.py[line:181]/DEBUG/  ===  success to update 36.250.156.152 proxy  ===
2019-Jun-09 16:58:06 proxyDBManager.py[line:181]/DEBUG/  ===  success to update 36.250.156.152 proxy  ===
2019-Jun-09 16:58:06 scraper.py[line:208]/ERROR/  Error downloading <GET http://www.alexa.cn/Gmw.cn>
Traceback (most recent call last):
  File "E:\Users\JohnParker\Anaconda3\lib\site-packages\scrapy\core\downloader\middleware.py", line 43, in process_request
    defer.returnValue((yield download_func(request=request,spider=spider)))
twisted.internet.error.TCPTimedOutError: TCP connection timed out: 10060: 由于连接方在一段时间后没有正确答复或连接的主机没有反应，连接尝试失败。.
2019-Jun-09 16:58:09 retry.py[line:91]/DEBUG/  Gave up retrying <GET http://www.alexa.cn/Babytree.com> (failed 3 times): Connection was refused by other side: 10061: 由于目标计算机积极拒绝，无法连接。.
2019-Jun-09 16:58:09 proxyDBManager.py[line:181]/DEBUG/  ===  success to update 121.232.148.197 proxy  ===
2019-Jun-09 16:58:09 proxyDBManager.py[line:181]/DEBUG/  ===  success to update 121.232.148.197 proxy  ===
2019-Jun-09 16:58:09 scraper.py[line:208]/ERROR/  Error downloading <GET http://www.alexa.cn/Babytree.com>
Traceback (most recent call last):
  File "E:\Users\JohnParker\Anaconda3\lib\site-packages\scrapy\core\downloader\middleware.py", line 43, in process_request
    defer.returnValue((yield download_func(request=request,spider=spider)))
twisted.internet.error.ConnectionRefusedError: Connection was refused by other side: 10061: 由于目标计算机积极拒绝，无法连接。.
2019-Jun-09 16:58:10 retry.py[line:91]/DEBUG/  Gave up retrying <GET http://www.alexa.cn/163.com> (failed 3 times): TCP connection timed out: 10060: 由于连接方在一段时间后没有正确答复或连接的主机没有反应，连接尝试失败。.
2019-Jun-09 16:58:10 proxyDBManager.py[line:181]/DEBUG/  ===  success to update 1.197.204.6 proxy  ===
2019-Jun-09 16:58:10 proxyDBManager.py[line:181]/DEBUG/  ===  success to update 1.197.204.6 proxy  ===
2019-Jun-09 16:58:11 scraper.py[line:208]/ERROR/  Error downloading <GET http://www.alexa.cn/163.com>
Traceback (most recent call last):
  File "E:\Users\JohnParker\Anaconda3\lib\site-packages\scrapy\core\downloader\middleware.py", line 43, in process_request
    defer.returnValue((yield download_func(request=request,spider=spider)))
twisted.internet.error.TCPTimedOutError: TCP connection timed out: 10060: 由于连接方在一段时间后没有正确答复或连接的主机没有反应，连接尝试失败。.
2019-Jun-09 16:58:19 retry.py[line:91]/DEBUG/  Gave up retrying <GET http://www.alexa.cn/Soso.com> (failed 3 times): TCP connection timed out: 10060: 由于连接方在一段时间后没有正确答复或连接的主机没有反应，连接尝试失败。.
2019-Jun-09 16:58:19 proxyDBManager.py[line:181]/DEBUG/  ===  success to update 1.197.204.6 proxy  ===
2019-Jun-09 16:58:19 proxyDBManager.py[line:181]/DEBUG/  ===  success to update 1.197.204.6 proxy  ===
2019-Jun-09 16:58:19 scraper.py[line:208]/ERROR/  Error downloading <GET http://www.alexa.cn/Soso.com>
Traceback (most recent call last):
  File "E:\Users\JohnParker\Anaconda3\lib\site-packages\scrapy\core\downloader\middleware.py", line 43, in process_request
    defer.returnValue((yield download_func(request=request,spider=spider)))
twisted.internet.error.TCPTimedOutError: TCP connection timed out: 10060: 由于连接方在一段时间后没有正确答复或连接的主机没有反应，连接尝试失败。.
2019-Jun-09 16:58:27 retry.py[line:91]/DEBUG/  Gave up retrying <GET http://www.alexa.cn/Sohu.com> (failed 3 times): TCP connection timed out: 10060: 由于连接方在一段时间后没有正确答复或连接的主机没有反应，连接尝试失败。.
2019-Jun-09 16:58:27 proxyDBManager.py[line:181]/DEBUG/  ===  success to update 58.22.206.196 proxy  ===
2019-Jun-09 16:58:27 proxyDBManager.py[line:181]/DEBUG/  ===  success to update 58.22.206.196 proxy  ===
2019-Jun-09 16:58:27 scraper.py[line:208]/ERROR/  Error downloading <GET http://www.alexa.cn/Sohu.com>
Traceback (most recent call last):
  File "E:\Users\JohnParker\Anaconda3\lib\site-packages\scrapy\core\downloader\middleware.py", line 43, in process_request
    defer.returnValue((yield download_func(request=request,spider=spider)))
twisted.internet.error.TCPTimedOutError: TCP connection timed out: 10060: 由于连接方在一段时间后没有正确答复或连接的主机没有反应，连接尝试失败。.
2019-Jun-09 16:58:28 engine.py[line:295]/INFO/  Closing spider (finished)
2019-Jun-09 16:58:28 statscollectors.py[line:47]/INFO/  Dumping Scrapy stats:
{'downloader/exception_count': 38,
 'downloader/exception_type_count/twisted.internet.error.ConnectionRefusedError': 5,
 'downloader/exception_type_count/twisted.internet.error.TCPTimedOutError': 32,
 'downloader/exception_type_count/twisted.web._newclient.ResponseNeverReceived': 1,
 'downloader/request_bytes': 22238,
 'downloader/request_count': 52,
 'downloader/request_method_count/GET': 52,
 'downloader/response_bytes': 116030,
 'downloader/response_count': 14,
 'downloader/response_status_count/200': 11,
 'downloader/response_status_count/500': 1,
 'downloader/response_status_count/503': 2,
 'finish_reason': 'finished',
 'finish_time': datetime.datetime(2019, 6, 9, 8, 58, 28, 71985),
 'httperror/response_ignored_count': 1,
 'httperror/response_ignored_status_count/500': 1,
 'item_scraped_count': 10,
 'log_count/DEBUG': 215,
 'log_count/ERROR': 11,
 'log_count/INFO': 14,
 'request_depth_max': 1,
 'response_received_count': 12,
 'retry/count': 30,
 'retry/max_reached': 11,
 'retry/reason_count/503 Service Unavailable': 2,
 'retry/reason_count/twisted.internet.error.ConnectionRefusedError': 3,
 'retry/reason_count/twisted.internet.error.TCPTimedOutError': 25,
 "robotstxt/exception_count/<class 'twisted.internet.error.TCPTimedOutError'>": 1,
 'robotstxt/request_count': 1,
 'scheduler/dequeued': 49,
 'scheduler/dequeued/memory': 49,
 'scheduler/enqueued': 49,
 'scheduler/enqueued/memory': 49,
 'spider_exceptions/InvalidURL': 1,
 'start_time': datetime.datetime(2019, 6, 9, 8, 54, 1, 973924)}
2019-Jun-09 16:58:28 engine.py[line:326]/INFO/  Spider closed (finished)
